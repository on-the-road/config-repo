一.将一个网址映射到一个特定的IP地址的过程就叫做域名解析。域名的解析工作由DNS服务器完成
DNS是一种协议，通过域名查找IP地址，或逆向通过IP地址反查域名
这里类同的概念，CDN是什么？与DNS有关系吗？
CDN -- Content Delivery Network，内容分发网络，是构建在网络之上的内容分发网络
与域名解析服务器(DNS)是两个概念...

cdn的工作原理:
其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”
使用户可以就近取得所需的内容，提高用户访问网站的响应速度
当用户访问已经加入CDN服务的网站时，首先通过DNS重定向技术确定最接近用户的最佳CDN节点
同时将用户的请求指向该节点。当用户的请求到达指定节点时，CDN的服务器（节点上的高速缓存）
负责将用户请求的内容提供给用户，具体流程为: 
用户在自己的浏览器中输入要访问的网站的域名，浏览器向本地DNS请求对该域名的解析，本地DNS将请求发到网站的主DNS
主DNS根据一系列的策略确定此时最适当的CDN节点，并将解析的结果（IP地址）发给用户
用户向给定的CDN节点请求相应网站的内容

二.Https -- 端口 443  Http -- 端口 80，这里需要说明 http/2.0协议是建立在https的基础之上的，也就是说如果想用http/2.0
首先必须是https的协议

三.目前HTTP协议的版本就是1.1,但是大部分服务器也支持1.0版本
主要区别在于1.1版本允许多个HTTP请求复用一个TCP连接，以加快传输速度
一个http请求由三部分组成：请求行，消息头，请求体

URI -- Uniform Resource Identifier 统一资源标识符、用字符串标识某一互联网资源
URL -- Uniform Resource Locator 统一资源定位符，标识资源的地点
url是uri的子集

四.DNS(Domain Name System 的缩写)
作用非常简单，就是根据域名查出IP地址。你可以把它想象成一本巨大的电话本。
举例来说，如果你要访问域名math.stackexchange.com
首先要通过DNS查出它的IP地址是151.101.129.69

五.DNS服务器，分级查询。域名的分类：
根域名：.root根域名.root对于所有域名都是一样的，所以平时是省略的
顶级域名：.com .cn .net等
次级域名：www.baidu.com这里的.baidu就是次级域名(二级域名)，这一级域名是用户可以注册的
三级域名(主机名)：再下一级是主机名（host），比如www.example.com里面的www
这是用户在自己的域里面为服务器分配的名称，是用户可以任意分配的
主机名.次级域名.顶级域名.根域名 # 即：host.sld.tld.root


六.为什么说http是无状态的短连接？
每个请求都是独立的，不具有事务的特点。与前面或是后面的请求没有直接的联系
keep-alive保持连接的时限。配置不当，是浪费资源
早期建立一个tcp连接，请求-响应结束，连接自动关闭

http的长连接
HTTP也可以建立长连接的，使用Connection:keep-alive，HTTP 1.1默认进行持久连接
HTTP1.1和HTTP1.0相比较而言，最大的区别就是增加了持久连接支持(貌似最新的 http1.0 可以显示的指定 keep-alive)
但还是无状态的，或者说是不可以信任的

什么时候用长连接，短连接？
长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况，每个TCP连接都需要三步握手，这需要时间
如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开
次处理时直接发送数据包就OK了，不用建立TCP连接
例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket创建也是对资源的浪费
而像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源
而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接
而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧
所以并发量大，但每个用户无需频繁操作情况下需用短连好，总之，长连接和短连接的选择要视情况而定

长连接和短连接还是有一些区别的
长连接，tcp三次握手后，操作系统会通过发送tcp心跳包来保证连接不会因为空闲时间限制被回收
    基于长连接客户端可以先发送一个请求，不用等服务端返回立即在发送一个请求
短连接，tcp三次握手后，请求一次等到收到回复后就会进行四次挥手断开连接

七.TCP/IP四层模型：
1.应用层 -- http、ftp、dns等均在这一层
2.传输层 -- tcp、udp等
3.网络层 -- 作用就是选择一条传输路径，IP协议等
4.数据链路层 -- 硬件上的范畴

这里所说的IP协议与IP地址不要混淆，不是一回事，IP(Internet Protocol)网际协议，作用就是把各种数据包传送给对方
而要保证确实传送到对方那里，需要两个重要的条件、ip地址和MAC地址

TCP三次握手详细理解：success -- established 建立连接成功。
1. A-->B
SYN -- 连接请求,此时 --> ACK=0 -- SYN-SENT
SYN=1  seq=x	
2. B-->A
SYN + ACK -- 确认连接加ACK包 -- SYN-RECD
SYN=1 ACK=1 seq=y ack=x+1
3. A-->B
ACK -- 确认包
ACK=1 seq =x+1 ack=y+1

tcp -- transimission control protocal -- 传输控制协议。
tcp -- 标志位 -- 六种标识
1. SYN -- synchronous -- 同步数据包序号
2. ACK -- acknowledgement -- 确认
3. PSH -- push -- 传送
4. FIN -- finish -- 结束
5. RST -- reset -- 重置
6. URG -- urgent -- 紧急 急迫的，强迫的

tcp -- 首部:固定20个字节
ACK -- TCP首部 序号：ACK = 1时有效，建立连接以后所有报文的ACK必须等于1

SYN -- 建立连接时，用来同步序号，当SYN = 1 ACK =0时，表示这是一个连接请求。对方若同意建立连接
则应在响应报文中使SYN=1和ACK=1. 因此,  SYN置1就表示这是一个连接请求或连接接受报文
TCP规定SYN=1时不能携带数据，但要消耗一个序号

FIN -- finish完结的意思。用来释放一个连接。当 FIN = 1 时，表明此报文段的发送方的数据已经发送完毕并要求释放连接
seq -- 序号，tcp传送中的字节流的每一个字节按顺序编号。序号占4个字节，0 - 2的32次方-1
ack -- 是期望对方继续发送的那个数据包的序列号，确认序号，ack=seq +1
seq -- 是数据包本身的序列号,这是为了连接以后传送数据用的

seq是序列号，这是为了连接以后传送数据用的，ack是对收到的数据包的确认，值是等待接收的数据包的序列号
在第一次消息发送中，A随机选取一个序列号作为自己的初始序号发送给B；第二次消息B使用ack对A的数据包进行确认
因为已经收到了序列号为x的数据包，准备接收序列号为x+1的包，所以ack=x+1，同时B告诉A自己的初始序列号
就是seq=y；第三条消息A告诉B收到了B的确认消息并准备建立连接，A自己此条消息的序列号是x+1，所以seq=x+1
而ack=y+1是表示A正准备接收B序列号为y+1的数据包

三次握手的原因：防止已失效的连接请求，突然被服务端收到，造成错误或是资源的浪费。

TCP四次挥手详细理解：释放连接
TCP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)，客户端或服务器均可主动发起挥手动作
一个FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据
1. A-->B
FIN=1 seq=u --- 进入 FIN-WAIT-1状态
2. B-->A 
ack=u+1,seq=v --- 进入 CLOSE-WATI状态
3. B-->A 
FIN=1 ack=u+1 seq=w ACK=1 --- 进入LAST-ACK状态
4. A-->B
ACK=1 ack=w+1 seq=u+1 ---进入 FIN-WAIT-2状态

为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？
这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的连接请求后，它可以把ACK和SYN(ACK起应答作用
而SYN起同步作用)放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了
但未必你所有的数据都全部发送给对方了，所以你可能未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后
再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的

主动关闭的一方在发送完对对方FIN报文的确认(ACK)报文后，会进入TIME_WAIT状态。TIME_WAIT状态也称为2MSL状态
什么是2MSL？MSL即Maximum Segment Lifetime，也就是报文最大生存时间，引用《TCP/IP详解》中的话
“它(MSL)是任何报文段被丢弃前在网络内的最长时间”，那么，2MSL也就是这个时间的2倍
其实我觉得没必要把这个MSL的确切含义搞明白，你所需要明白的是，当TCP连接完成四个报文段的交换时
主动关闭的一方将继续等待一定时间(2-4分钟)，即使两端的应用程序结束。你可以写代码试试，然后用setstat查看下

为什么需要2MSL？根据《TCP/IP详解》和《The TCP/IP Guide》中的说法，有两个原因：
其一，保证发送的ACK会成功发送到对方，如何保证？我觉得可能是通过超时计时器发送。这个就很难用代码演示了
其二，报文可能会被混淆，意思是说，其他时候的连接可能会被当作本次的连接

TCP协议和UDP协议的区别是什么？
TCP协议是有连接的，有连接的意思是开始传输实际数据之前TCP的客户端和服务器端必须通过三次握手建立连接
会话结束之后也要结束连接，而UDP是无连接的。TCP协议保证数据按序发送，按序到达，提供超时重传来保证可靠性
但是UDP不保证按序到达，甚至不保证到达，只是努力交付，即便是按序发送的序列，也不保证按序送到
TCP协议所需资源多，TCP首部需20个字节（不算可选项），UDP首部字段只需8个字节。TCP有流量控制和拥塞控制
UDP没有，网络拥堵不会影响发送端的发送速率，TCP是一对一的连接，而UDP则可以支持一对一，多对多，一对多的通信
TCP面向的是字节流的服务，UDP面向的是报文的服务，TCP的半关闭能力：提供了连接的一端在结束了它数据发送之后
还能接受来自另一端的数据

这里需要了解下字节流和报文的异同？
字节就是散乱的数据，报文就是添加了标记，封装后的数据。
一般TCP/IP的应用层或者OSI的会话、表示、应用层把数据称为数据或者信息
到了传输层把数据称为报文，到了最底层就是比特流了也就是字节流

tcp的粘包和拆包问题？
无论是服务端还是客户端，当我们读取或发送消息的时候，都要考虑tcp底层的粘包、拆包机制
tcp是一个‘流’协议，所谓流就是没有界限的一串数据，tcp底层并不了解上层业务数据的具体含义，他会根据tcp缓冲区的实际情况
进行包的划分，所以在业务上认为，一个完整的包可能被tcp拆分成多个包进行发送，同时也有可能把多个小的包封装成一个大的数据
包进行发送，这就是所谓的tcp粘包和拆包问题

tcp滑动窗口原理
就是接收端可以根据自己的状况通告窗口大小，从而控制发送端的接收，进行流量控制
win = 0，则发送端停止发送数据。当接受端滑动窗口可用时即win > 0，接收方发送一个窗口通告，告知发送方已经有接收数据的能力了
可以发送数据包了，发送方接着发送数据。以下是关于滑动窗口的一个视频地址...
http://v.youku.com/v_show/id_XNDg1NDUyMDUy.html

八.持久连接，HTTP1.1默认进行持久连接，即连接重用模式，HTTP1.0中默认是关闭的，如果开启则在请求头中添加Connection: Keep-Alive
在响应头信息中可以看到这个key-value，一般服务器端都会设置keep-alive超时时间，同时还会设置一个最大请求数，两者超过其一服务器
会自动断开连接。Keep-Alive模式，客户端如何判断请求所得到的响应数据已经接收完成？
1.web服务器在返回给客户端HTTP头信息中发送一个Content-Length(返回信息正文的长度)头，客户端根据这个就可以判断数据是否读完
比如说响应的是一个静态的页面或是一张图片

但是有些时候是没有办法准确的拿到Content-Length这个头的，比如说一个动态的页面
我们在做WEB性能优化时，有一个重要的指标叫 TTFB（Time To First Byte），它代表的是从客户端发出请求到收到响应的第一个
字节所花费的时间，可想而知服务端为了计算响应的长度而缓存所有的响应内容，跟更短的TTFB理念背道而驰

但在HTTP报文中，实体一定要在头部之后，顺序不能颠倒，为此我们需要一个新的机制：不依赖头部的长度信息，也能知道实体的边界

2.只能先开一个足够大的内存空间，等内容全部生成好再计算。但这样做一方面需要更大的内存开销，另一方面也会让客户端等更久
这时候Transfer-Encoding: chunked
响应头就派上用场了，chunk编码将数据分成一块一块的发生，该响应头表示响应体内容是分块传输，此时服务器可以将数据一块一块地分
块响应给浏览器而不必一次性全部响应，待浏览器接收到全部分块后就表示响应结束，最后一块数据长度是0，比如0\r\n
Chunked编码将使用若干个Chunk串连而成，由一个标明长度为0的chunk标示结束。每个Chunk分为头部和正文两部分
头部内容指定正文的字节总数(十六进制的数字)，正文部分就是指定长度的实际内容，两部分之间用回车换行(CRLF)隔开

八.OKHttp相关
Square公司开发的OkHttp，是一个专注于性能和易用性的HTTP客户端，OKHttp库的设计和实现的首要目标是高效!
OkHttp提供了对GZIP的默认支持来降低传输内容的大小。OkHttp也提供了对HTTP响应的缓存机制，支持http2.0规范
可以避免不必要的网络请求。当网络出现问题时，OkHttp会自动重试一个主机的多个IP地址，OkHttp是一个很棒HTTP客户端

支持SPDY, 可以合并多个到同一个主机的请求。使用连接池技术减少请求的延迟(如果SPDY是可用的话)
使用GZIP压缩减少传输的数据量，缓存响应避免重复的网络请求
SPDY---是对HTTP协议的增强。新协议的功能包括数据流的多路复用、请求优先级以及HTTP报头压缩
SPDY -- 取自speedy、迅速的，敏捷的，旨在解决HTTP的性能瓶颈，缩短web页面的加载时间，2010年由Google发布
陆续出现的Ajax和Comet等提高易用性的技术，一定程度上使HTTP得到了改善，但HTTP协议本身的限制也令人有些束手无策。为了进行根本性
的改善，需要有一些协议层面上的改动。处于持续开发状态中的SPDY协议，正是为了在协议级别消除HTTP所遭遇的瓶颈

使用SPDY后，HTTP协议额外获得以下功能
多路复用流
通过单一的TCP连接，可以无限制处理多个HTTP请求。所有请求的处理都在一条TCP连接上完成，因此TCP的处理效率得到提高

赋予请求优先级
SPDY不仅可以无限制地并发处理请求，还可以给请求逐个分配优先级顺序。这样主要是为了在发送多个请求时
解决因带宽低而导致响应变慢的问题

压缩HTTP首部 
压缩HTTP请求和响应的首部。这样一来，通信产生的数据包数量和发送的字节数就更少了

推送功能
支持服务器主动向客户端推送数据的功能。这样，服务器可直接发送数据，而不必等待客户端的请求

服务器提示功能
服务器可以主动提示客户端请求所需的资源。由于在客户端发现资源之前就可以获知资源的存在，因此在资源已缓存等情况下
可以避免发送不必要的请求


九.抓包工具 -- wireshark(开源的)，能拦截https请求的fiddler[ˈfɪdlər] -- 小提琴家，游手好闲的人

十.HTTP响应状态码类别
1xx -- 信息性状态码，收到的请求正在处理
2xx -- 成功状态码，请求处理完毕
3xx -- 重定向状态码，需要进行附加操作以完成请求
4xx -- Client Error(客户端错误状态码)，服务器无法处理请求
5xx -- Server Error(服务器错误状态码)，服务器处理请求出错

    http重定向相关内容：在HTTP协议中，重定向操作由服务器通过发送特殊的响应（即redirects）而触发
    HTTP协议的重定向响应的状态码为3xx。浏览器在接收到重定向响应的时候，会采用该响应提供的新的URL，并立即进行加载
    大多数情况下，除了会有一小部分性能损失之外，重定向操作对于用户来说是不可见的
    不同类型的重定向映射可以划分为三个类别：永久重定向，临时重定向和特殊重定向
    

十一.HTTP/1.1 规范允许一台HTTP服务器搭建多个Web站点，这是因为利用了虚拟主机(Virtual Host)的功能
实际物理层面只有一台，表面看上去有多台，通过域名解析，当请求到达服务器时，已经是以IP地址的形式访问了
在相同的IP地址下，由于虚拟主机可以寄存多个不同主机名和域名的Web网站，因此在发送HTTP请求时
必须在Host首部内完整指定主机名或域名的URI。example -- Host: www.hackr.jp

代理时怎么回事？
代理是一种有转发功能的应用程序，它扮演了位于服务器和客户端“中间人”的角色，接收由客户端发送的请求并转发给服务器
同时也接收服务器返回的响应并转发给客户端
使用代理服务器的理由有：利用缓存技术减少网络带宽的流量，组织内部针对特定网站的访问控制，以获取访问日志为主要目的，等等
代理使用方法，一种是是否会使用缓存，另一种是否会修改报文

缓存代理
代理转发响应时，缓存代理（Caching Proxy）会预先将资源的副本保存在代理服务器上，当代理再次接收到对相同资源的请求时
就可以不从源服务器那里获取资源，而是将之前缓存的资源作为响应返回。所以这里会存在一个问题，即缓存资源的有效性？
即使存在缓存，也会因为客户端的要求、缓存的有效期等因素，向源服务器确认资源的有效性。若判断缓存失效，缓存服务器将会再次
从源服务器上获取“新”资源

透明代理
转发请求或响应时，不对报文做任何加工的代理类型被称为透明代理（Transparent Proxy）。反之，对报文内容进行加工的代理被
称为非透明代理

网关是怎么回事？
网关是转发其他服务器通信数据的服务器，接收从客户端发送来的请求时，它就像自己拥有资源的源服务器一样对请求进行处理
有时客户端可能都不会察觉，自己的通信目标是一个网关。网关的工作机制和代理十分相似，利用网关能提高通信的安全性
而网关能使通信线路上的服务器提供非HTTP协议服务（客户端通过http协议 --> 网关通过其他协议 -->目标服务器）

隧道是怎么回事？
隧道是在相隔甚远的客户端和服务器两者之间进行中转，并保持双方通信连接的应用程序
隧道可按要求建立起一条与其他服务器的通信线路，届时使用SSL等加密手段进行通信。隧道的目的是确保客户端能与服务器进行安全的通信
隧道本身不会去解析HTTP请求。也就是说，请求保持原样中转给之后的服务器。隧道会在通信双方断开连接时结束
通过隧道的传输，可以和远距离的服务器安全通信。隧道本身是透明的，客户端不用在意隧道的存在 

十二.首部字段，请求头字段
Cache-Control: no-store，不进行缓存
               no-cache，不缓存过期资源
Referrer: 请求的url是从哪个web页面发起的，注意是 Referrer而不是 Referer!

十三.HTTP通信的缺点
通信使用明文（不加密），内容可能会被窃听
不验证通信方的身份，因此有可能遭遇伪装  -- DoS攻击(Denial of service)，拒绝服务攻击
无法证明报文的完整性，所以有可能已遭篡改 -- MIMT攻击(Man-in-the-Middle attack)，中间人攻击

HTTP + 加密 + 认证 + 完整性保护 = HTTPS 
通常，HTTP直接和TCP通信。当使用SSL时，则演变成先和SSL通信，再由SSL和TCP通信了。HTTPS，其实就是身披SSL协议这层外壳的HTTP



