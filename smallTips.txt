
1.oss -- open storage service  阿里云存储服务..
ios -- 文件后缀ipa，android -- 文件后缀apk
trade off理解---是“利”与“弊”的权衡
CSRF攻击：(跨站点请求伪造) (Cross-Site-Request-Forgery)
WEB-INF目录下的JSP页面不能通过地址栏直接访问，WEB-INF目录下的文件不能直接被访问主要是出于安全考虑
thymeleaf [taim li:f]--(百里香叶)，Thymeleaf 是一个跟 Velocity、FreeMarker类似的模板引擎，它可以完全替代JSP
MD5加密单向的，不可逆的，登录密码比对，只能是先MD5加密，然后用两个加密后的密码进行比对
linux --->存储数据的最小单位：数据块：一个数据块=512字节0.5k ...
在JavaScript内部，整数和浮点数是同样的储存方法，所以3和3.0被视为同一个值
java.net.UnknownHostException  ---->域名解析异常
javascript默认Unicode编码，统一起见所有字符都是2个字节，在js里用length来求字符串长度的时候是指字符串的字符数

修改jenkins端口
	Java -jar jenkins.war --httpPort=8081

2.网络相关知识:
要判断两个IP地址是不是在同一个网段，就将它们的IP地址分别与子网掩码做与运算，得到的结果-->网络号，如果网络号相同

3.多线程相关
守护线程Daemon和用户线程User，任何线程在启动(start)之前都可以设置是否是Daemon
进程，是系统分配资源的最小单元，线程是系统调度的最小单元
死锁，是指两个或两个以上的进程(或线程)在执行过程中，因争抢同一资源而造成的互相等待的现象
若无外力作用，它们都将无法推进下去
Java有一种特别的线程叫做守护线程。这种线程的优先级非常低，
通常在程序里没有其他线程运行时才会执行它
当守护线程是程序里唯一在运行的线程时，JVM会结束守护线程并终止程序
JAVA中最典型的这种类型线程的代表就是垃圾回收线程

Future:类型作用, Future是一个接口
	1.判断任务是否执行完成
	2.能够中断任务
	3.能够获取任务执行结果

4.tomcat -- 修改 java-jdk版本:
	windows系统里，tomcat默认是使用系统变量JAVA_HOME的jdk版本，如果需要更换，可以在配置文件手动指定。
	在bin\catalina.bat和bin\setclasspath.bat文件，记事本打开编辑，开头的空白处加上：
	set JAVA_HOME=D:\jdk\jdk1.8.0_31
	set JRE_HOME=D:\jdk\jdk1.8.0_31\jre

5.服务器操作系统：windows,linux,netware,unix
	个人桌面操作系统：个人pc
	嵌入式操作系统：Andriod ios....

6.JSON.stringify() 方法将JavaScript值转换为JSON字符串0
	JSON.parse() 方法解析一个JSON字符串，构造由字符串描述的JavaScript值或对象

7.jQuery中each类似于javascript的for循环
	但不同于for循环的是在each里面不能使用break结束循环，
	也不能使用continue来结束本次循环，想要实现类似的功能就只能用return,
		break           用return false
		continue        用return ture

22. javascript中prototype允许我们在创建对象之后来改变对象或类的行为，
	并且这些通过prototype属性添加的字段或方法所有对象实例是共享的

24. RPC 是什么？
		Remote Procedure Call Protocol  ----远程过程调用协议
	OOM是什么？
		Out Of Memory 内存溢出

25. Hbase :-----------HBase – Hadoop Database
		HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。

		另一个不同的是HBase基于列的而不是基于行的模式。
		HBase是Apache的Hadoop项目的子项目

26. JWT --- json web token
	Session的状态是存储在服务器端，客户端只有session id；而Token的状态是存储在客户端
	一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名

27.windows -- 刷新Dns缓存命令：
	ipconfig/flushdns

28.static 关键字的作用....
	1.可以修饰成员变量，修饰成员方法，可以修饰内部类（静态内部类...）。
	2.可以修饰代码块（静态代码块）。
	3.静态导包。import static com..ClassName.*; 意思是本类中导入这个类里的所有静态方法
	调用时直接 方法名即可...  而不用：ClassName.方法名()这样调用。

29. mybatis中 #与 $的区别.....
		# 将传入的数据都当成一个字符串来对待，对传入的数据自动添加一对引号....(这里似乎不能是双引号？？？？？)
		$ 将传入的参数直接拼接在sql上，不做任何的处理... 容易导致sql注入.....order by 的时候 必须用 ${param}

30. sleep()和wait()的区别：
		sleep()是线程类中的一个静态方法，让当前线程睡眠几秒，但并不会释放对象锁
		vait()是Object类中的方法，该方法让当前线程处于等待状态，并释放当前对象锁
		该线程想要再次执行时，需要notify()方法唤醒

31. js中两个变量怎么比较大小？
	js中var定义的变量默认是字符串类型，单纯的比较会出现错误，所以先转化成int类型 --- parseInt() 一下

32. 普通类不能包含抽象方法，抽象类可以包含抽象方法
	抽象类不能直接实例化，普通类可以直接实例化
	接口不能继承抽象类，抽象类中可以有方法体，那么该接口也会继承抽象类里面的非抽象方法
	这就与接口的定义矛盾了
	抽象类可以实现一个或多个接口，接口可以同时继承多个接口
	接口没有构造方法，抽象类可以有构造方法
	抽象类可以继承普通类，前提是普通类的构造方法可以被子类访问到



33. tomcat设置jvm内存 要在启动的时候，所以在启动脚本中配置
	JAVA_OPTS='-Xms512m -Xmx1024m'表示初始化分配内存为512MB，可以使用的最大内存为1024MB
	--- windows catalian.bat  catalian.sh
	好比，启动一个java程序，其实主入口是main方法，所以设置jvm参数能传到main方法中就可以

34. 路径问题： ./ 表示当前目录下，
	这个当前的意思并非是包或类 所在的当前目录，而是相对整个项目来说的，
	所以应该是 -- 当前类或包所在项目的根目录(即和src目录是同级目录)

35. 数学中质数的定义：质数又称为素数，有无限多个，大于1的自然数，并且只能被1和其自身整除
	0是整数，但0既不是正整数也不是负整数
	大于0的整数 -- 正整数
	小于0的整数 -- 负整数

37. maven --->GAV 是什么? 即：groupId, atrifactId, version
	parent标签 -- 相当于java中的继承

39. "新建"和"终止"这两种状态其实并不是线程的状态，而是java.lang.Thread对象的状态。
    可以说，处于"新建"和"终止"状态的"线程"其实并不是线程，而只是代表着一个线程对象而已。
    所以我们把"新建(NEW)"和"终止(TERMINATED)"两种状态去掉，那么线程的状态有：
      就绪状态(可运行状态)
      运行状态
      阻塞状态

40. 垃圾收集的时候，怎么确定一个对象是垃圾对象？根搜索算法的基本思路就是通过一系列名为
	”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)
	当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可达的。
	可作为 GC Roots（根集）的对象：
	1.栈帧中的局部变量所引用的对象
	2.本地方法栈中的JNI所引用的对象
	3.方法区的静态变量和常量所引用的对象
	----方法区中同样存在垃圾回收：废弃的常量和无用的类



42. java中到底是否存在引用传递？ -- 重点
	-- 不存在，java方法传参的时候不存在引用传递，都是值传递

43. Exception && RuntimeException层级关系
	Throwable ---|Exception --| RuntimeException
		         |Error
	以上都是类，没有接口

44. 缓存与缓冲的区别？
	简单来说：缓存(cache)是加速从硬盘中读取数据的
		      缓冲(buffer)是加速数据写入磁盘的
    都是站在磁盘角度来说的

45. wait()方法应该在循环中调用更合适...
	Jit --即时编译：just in time compilation

46. 表级锁：不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低
	行级锁：会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高

47. 由于InnoDB预设是Row-Level Lock，所以只有「明确」的指定索引，
	MySQL才会执行Row lock(只锁住被选取的资料例),否则MySQL将会把整个资料表单给锁住

	补充 - varchar(100)中的100表示当前字符集的字符长度（这里的字符包括英文字符、汉字等），而不是字节长度！
	同时mysql中varchar的定义是变长（0-65535）
	MySQL要求一个行的定义长度不能超过65535(包括多个字段)，所以这里的65535是字节数
	而varchar的最大有效长度取决于最大行大小
	utf-8 一个汉字占3个字节，utf-16 一个汉字占4个字节

48. 什么是cookie? 与session的区别？
	cookie是存储key-value的文件，是客户端保存用户信息的一种机制，也是实现session的一种方式
	是http协议的一种扩展。务必记住，它是由服务器将cookie添加到response里一并返回给客户端
	然后客户端会自动把response里的cookie接收下来并且保存到本地，
	下次发出请求的时候就会把cookie附加在request里，
	服务器在根据request里的cookie遍历搜索是否有与之符合的信息
	如果服务器返回cookie，存储在响应内容里面head头的字段叫做什么？
	Set-Cookie响应头部 --- Cookie请求头部

50. oracle中 rownum和rowid的区别？
	rownum是根据查询结果给每一条记录分配一个逻辑编号，从1开始
	rowid是物理结构上的，每条记录插入到数据库时，都会有一个唯一的物理编号，是一个18位的字符串

51. JMS -- 是java的api，AMQP--是一种高级队列协议

52. java5.0提供了java.util.concurrent(简称JUC包)
	juc包下的队列，采用加锁的方式保证线程安全，不加锁的对列都是无界的
	这里的无界(无法保证队列的长度在限定的范围，无界就是没有设置队列的size，可以一直入列，jvm内存会被撑爆)
	false-sharing:伪共享

53. cpu -- 高速缓存(简称缓存：L1,L2,L3)基本组成单位(cache line 64byte) 

54. 使用docker命令：docker ps -a，区分容器和镜像的概念，查询当前系统的(运行着的)容器
	docker image -- 才是查询当前系统的镜像

55. 网络名词，桥接是怎么理解？
	在两个网络之间搭一个桥，将两个网络连接到一起。通过一台设备把网络串联起来
	对网络数据包从一个网络转发到另一个网络

56. Java中生成随机数的类Random，这是一个线程安全的类，内部使用CAS来实现线程安全，这个类
	并不是真正的随机，而是伪随机，意思就是生成的随机数是有一定的规律的。
	juc包下的ThreadLocalRandom，从类的命名，就可以看出实现原理类似于ThreadLocal
	seed种子是保存在每个线程中的，也是根据每个线程中的seed来计算新的种子的，这样就避免了竞争的问题

57. CAS -- compare-and-swap (比较并替换),是一种实现并发算法时常用到的技术
	CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B
	CAS虽然很高效的解决了原子操作问题，但是CAS仍然存在三大问题
		--循环时间长开销很大
		--只能保证一个共享变量的原子操作
		--ABA问题

58. ABA问题？-- 如果内存地址V初次读取的值是A,并且在准备赋值的时候检查到它的值仍然为A,那我们就能说它的
	值没有被其他线程改变过了吗？
	如果在这段期间它的值曾经被改成了B,后来又被改回为A,那CAS操作就会误认为它从来没有被改变过
	这个漏洞称为CAS操作的“ABA”问题.Java并发包为了解决这个问题,提供了一个带有标记的原子引用类“AtomicStampedReference”
	它可以通过控制变量值的版本来保证CAS的正确性.因此,在使用CAS前要考虑清楚“ABA”问题是否会影响程序并发的正确性
	如果需要解决ABA问题,改用传统的互斥同步可能会比原子类更高效

59. ThreadLocalRandom -- jdk1.7之后提供的，用来在并发场景下代替Random。用法比较简单
	ThreadLocalRandom.current().nextInt();
	ThreadLocalRandom.current().nextInt(10);
	减少了对象的维护成本，内部实现也更轻量级，所以ThreadLocalRandom性能很高

60. JMH是什么？它是一个微基准测试框架，什么是微基准？微基准是一个旨在衡量非常小以及特定代码性能的基准
	Java Mircobenchmark Harness 
	harness -- 马具，系带

62. 分布式ID -- 
	uuid ,数据库，redis,zookeeper，数据库分段+服务缓存ID，雪花算法(snowflake) flake-- 碎片，薄片



64. 分布式锁的一些特点
	a. 互斥性，互斥性是最基本，但是分布式锁需要保证在不同节点的不同线程的互斥
	b. 可重入性，同一个节点上的同一个线程如果获取了锁之后那么也可以再次获取这个锁
	c. 锁超时，和本地锁一样支持锁超时，防止死锁
	d. 高效，高可用，加锁和解锁需要高效，同时也需要保证高可用防止分布式锁失效，可以增加降级
	e. 支持阻塞和非阻塞，和ReentrantLock一样支持lock和trylock以及tryLock(long timeOut)

65. 实现分布式锁的几种方式
	mysql -- select .... from table for update
	zookeeper -- 第三方包 curator 
	redis -- 实现分布式锁 setNx(set if not exist) 如果不存在则更新
		这里有个问题，加锁了之后如果机器宕机那么这个锁就不会得到释放所以会加入过期时间
		加入过期时间需要和setNx同一个原子操作，在Redis2.8之前我们需要使用Lua脚本达到我们的目的
		但是redis2.8之后redis支持nx和ex操作是同一原子操作
		java客户端 redission
	google自研的chubby

67. Java GC的时候会发生 STW (stop-the-world)

68. 时间跳跃，分为人为调整和NTP自动调整
	NTP -- Network Time Protocol 是计算机时间同步的一种协议

69. Token失效问题？
	无状态JWT令牌(Stateless JWT token)发放出去之后
	不能通过服务器端让令牌失效，必须等到过期时间过才会失去效用

70. spring-cloud 的两个负载均衡组件
	ribbon是对服务之间调用做负载，是服务之间的负载均衡，zuul是可以对外部请求做负载均衡

71. 二分查找法于1946年公布，第一个没有bug的二分查找程序出现于1962年

72. 如果a的x次方等于N (a > 0 && a != 1)那么数x叫做以a为底N的对数
    记作x=logaN 其中a叫做对数的底数，N叫做真数
    ===> 以a为底的N的对数 二分查找的时候大概进行的次数为：㏒₂ⁿ次
	对数换底公式:
	logaN * lognA = 1
	logaN = lgn/lga

73. 列出几种运行型异常：
	ArithmeticException,BufferOverflowException
	ClassCastException,IndexOutOfBoundsException
	NullPointerException

74. 列出几种检查型异常：
	ClassNotFoundException,IOException
	FileNotFoundException等。
	构造方法可以抛出异常------

77. Comparable -- 接口可以认为是一个内比较器，实现了Comparable接口的类有一个特点，就是这些
	类的实例是可以互相比较的，至于具体和另一个实现了Comparable接口的类如何比较，则依赖compareTo方法的实现
	compareTo方法也被称为自然比较法
	compareTo方法的返回值是int，有三种情况：
	1、比较者大于被比较者（也就是compareTo方法里面的对象），那么返回正整数
	2、比较者等于被比较者，那么返回0
	3、比较者小于被比较者，那么返回负整数

78. Comparator -- 接口可以认为是一个外比较器，有两种情况可以使用实现Comparator接口的方式
	1、一个对象不支持自己和自己比较（没有实现Comparable接口），但是又想对两个对象进行比较
	2、一个对象实现了Comparable接口，但是开发者认为compareTo方法中的比较方式并不是自己想要的那种比较方式
	compare方法的返回值是int，有三种情况同上...
	Comparator要满足自反性，传递性，对称性
		1） 自反性：x，y的比较结果和y，x的比较结果相反
		2） 传递性：x>y,y>z,则x>z
		3） 对称性：x=y,则x,z比较结果和y，z比较结果相同

79. 综合77，78个人认为Comparable和Comparator两者只是方法签名不同，比较规则都是自己实现
	Comparable --> compareTo 接受一个参数
	Comparator --> compare 接受两个参数

80. awk：awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑
    awk在其对数据分析并生成报告时，显得尤为强大，简单来说awk就是把文件逐行的读入
	以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理

81. 实现线程同步的两种方式：
	1>使用 synchronized关键字，搭配 wati()和 notify()方法
		同步方法，synchronized可以修饰静态方法
		同步代码块，synchronized可以修饰代码块

	2>关键字volatile  
		a.volatile关键字为域变量的访问提供了一种免锁机制
		b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新 
		c.因此每次使用该域就要重新计算，而不是使用缓存中的值 
		d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量
		e.volatile不能保证线程安全性

		多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法 
    	用final域，有锁保护的域和volatile域可以避免非同步的问题

	3>ReentrantLock 可重入锁
		这里着重介绍下，与多线程并发执行的线程安全不同
		可重入强调对单个线程执行时重新进入同一个子程序仍然是安全的
		通俗来说：当线程请求一个由其它线程持有的对象锁时，该线程会阻塞
		而当线程请求由自己持有的对象锁时，如果该锁是重入锁，请求就会成功，否则阻塞
		synchronized是可重入锁！！！！！
		同一线程对同一个对象锁是可重入的，而且同一个线程可以获取同一把锁多次，也就是可以多次重入
		因为java线程是基于“每线程（per-thread）”，而不是基于“每调用（per-invocation）”的
		java中线程获得对象锁的操作是以线程为粒度的，per-invocation互斥体获得对象锁的操作是以每调用作为粒度的

		可重入锁的原理或是机制？
		重入锁实现可重入性原理或机制是：每一个锁关联一个线程持有者和计数器
		当计数器为0时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而调用相应的方法
		当某一线程请求成功后，JVM会记下锁的持有线程，并且将计数器置为1；此时其它线程请求该锁
		则必须等待；而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增
		当线程退出同步代码块时，计数器会递减，如果计数器为0，则释放该锁

	4>使用局部变量实现线程同步 
		如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本
		副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响
		使用完ThreadLocal，记得要进行remove操作，不然可能会内存溢出，一般使用的时候是先set再get操作

	5>使用阻塞队列实现线程同步，例如LinkedBlockingQueue

	6>使用原子变量实现线程同步，什么是原子变量？
	需要使用线程同步的根本原因在于对普通变量的操作不是原子的！
	例如，AtomicInteger -- 表示用原子的方式更新int的值，但是其不能替换Integer


82. 不管是32位的JVM还是64位的JVM，对于long和double类型（64位）变量的读写都不是原子性的，
	每次操作32位

83. 四种会话跟踪技术：能使得http协议变成有状态的
	1>URL重写
	2>表单隐藏域
	3>cookie
	4>session

84. 代理种类：
	jdk动态代理 -->通过接口的方式
	ciglib -->通过目标类子类的字节编码技术

85.自定义线程池大小经验(非本人的)，网上搜集的
   如果是CPU密集型应用，则线程池大小设置为N+1
   如果是IO密集型应用，则线程池大小设置为2N+1

   我们不妨想一下，为啥Nginx内部仅仅使用了4个线程，其性能就大大超越了100个进程的Apache HTTPD呢？
   追究其原因的话，回想一下计算机科学的基础知识，答案其实非常明显。要知道，即使是单核CPU的计算机也能“同时”运行着数百个线程
   但我们其实都知道，这只不过是操作系统快速切换时间片，跟我们玩的一个小把戏罢了。一核CPU同一时刻只能执行一个线程，然后操作系统切换上下文
   CPU核心快速调度，执行另一个线程的代码，不停反复，给我们造成了所有进程同时运行假象
   其实，在一核CPU的机器上，顺序执行A和B，永远比通过时间分片切换“同时”执行A和B要快，其中原因，学过操作系统这门课程的童鞋应该很清楚
   一旦线程的数量超过了CPU核心的数量，再增加线程数系统就只会更慢，而不是更快，因为这里涉及到上下文切换耗费的额外的性能
   在这段（"I/O等待"）时间内，线程是处于“阻塞”等待状态，也就是说没干啥正事！此时操作系统可以将这个空闲的CPU核心用于服务其他线程
   我们可以总结一下，当你的线程处理的是I/O密集型业务时，便可以让线程/连接数设置的比CPU核心大一些，这样就能够在同样的时间内
   完成更多的工作，提升吞吐量。更少的阻塞，更少的线程（更接近于CPU核心数）会发挥出更高的性能。只有当阻塞密集时，更多的线程数
   才能发挥出更好的性能

   数据库连接池中的连接数量大小应该设置成：数据库能够同时有效进行的查询任务数（通常情况下来说不会高于2*CPU核心数）

86. Super表示当前类的父类对象
	This表示当前类的对象

87. Tomcat的三个最重要的启动脚本:
	startup.bat
	catalina.bat
	setclasspath.bat
	执行startup.bat脚本主要做了以下几件事:
	设置 CATALINA_HOME 环境变量的值
	找到 catalina.bat 脚本
	调用 catalina.bat 脚本, 并把参数传过去

88. 静态的方法或是环境中不能调用非静态的方法或是变量

89. 在学到通过反射获取集合的add方法，可绕过泛型的限制的，用下面的方式成功绕过了你泛型
    ArrayList<Integer> collections1 = new ArrayList<Integer>()
	collections1.getClass().getMethod("add",Object.class).invoke(collections1,"aaa")
	System.out.println(collections.get(0));//可获得正确的输出

	java中的泛型是伪泛型

90. maven的一个标签：
	<scope>标签：
	<compile> --编译范围
	<system> --系统范围
	<test> -- 测试范围
	<provided> -- 已提供范围
	<runtime> -- 运行时范围
	<import> -- 它只使用在<dependencyManagement>中，表示从其它的pom中导入dependency的配置

91. LRU算法 -- Least Recently Used(最近最久未使用) -- 缓存淘汰算法
	LRU算法的设计原则是：如果一个数据在最近一段时间没有被访问到,那么在将来它被访问的可能性也很小
	也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰
	实现方式: LinkedHashMap
	LinkedHashMap底层就是用的HashMap加双链表实现的,而且本身已经实现了有序存储
	此外LinkedHashMap中本身就实现了一个方法removeEldestEntry用于判断是否需要移除最不常读取的数
	方法默认是直接返回false,不会移除元素,所以需要重写该方法,即当缓存满后就移除最不常用的数

92. LinkedHashMap -- 详解
	HashMap和双向链表合二为一即是LinkedHashMap。所谓LinkedHashMap,其落脚点在HashMap
	因此更准确地说,它是一个将所有Entry节点链入一个双向链表的HashMap。由于LinkedHashMap是HashMap的子类
	所以LinkedHashMap自然会拥有HashMap的所有特性

93. IntegerCache: Integer内部类，第一次初始化的时候，cache数组会存储[-128---127]这些常量

94. SSO -- Single Sign On(单点登陆)
	是指在多系统应用群中登录一个系统，便可在其他所有系统中得到授权而无需再次登录，包括单点登录与单点注销两部分

98. 消息队列的幂等性？其实就是消息不被重复消费

99. Kong -- 是一个云原生，高效，可扩展的分布式API网关。其核心价值在于高性能和可扩展性
	OpenResty -- (又称：ngx_openresty)是一个基于NGINX的可伸缩的Web 平台，由中国人章亦春发起，提供了很多高质量的第三方模块

100. 其实MD4,MD5,SHA1,SHA256,SHA512...都是散列算法的一种(hash算法，或是叫做摘要算法，是一个单向的函数)
	 f(date) = digest 容易
	 但是用digest反推data很难

101. idea的一些插件
	 JProfiler --- 性能分析工具
	 mybatis-plugin --- mybatis插件(收费)
	 activate-power-mode --- 敲代码炫酷效果
	 Background Image Plus --- 自己设置背景图片

102. String.hashCode()方法中 数字32的意义
	 一: 乘法运算可以被 -- 移位和减法运算取代
	 31*i == (32-1)*i == (i << 5) - i，这样使得jvm便于优化

	 二: 设计哈希算法时，一般会选择一个质数(可能是降低哈希冲突的概率)
	 而选择31(而不是选择2或101)，使哈希值分布在一个均匀的区间内
	 hash冲突较小，内存不易溢出

	 综上： 乘子31是个不错的选择

103. 大家来华为，包括我自己，就是来赚钱的。加班是辛苦，但是有钱赚啊。其他的，一概都是扯淡
	 有能力给钱，甚至能给超出他们预期的钱，这才是一家公司最能体现情怀的地方

104. (消息中间件)MQ的解决了什么问题？
	 一：异步处理
	 二：流量削峰
	 三：日志处理
	 四：应用解耦
	 实时性高的应用不宜用消息队列

105. Service Mesh -- 服务网格，下一代的微服务?
	 什么是服务网格：首先服务网格是一个基础设施层，功能在于处理服务间通信，职责是负责实现请求的可靠传递
	 在实践中，服务网格通常实现为轻量级网络代理，通常与应用程序部署在一起，但是对应用程序透明

106. CNCF -- (Cloud Native Computing Foundation)
	 云原生应用计算基金会

107. 云计算到底怎么理解？
 	 通俗来说，云计算服务其实就是让计算、存储、网络、数据、算法、应用等软硬件资源像电一样，随时随地、即插即用

 	 云计算是一种模型：
	 它可以实现随时随地、便捷地、随需应变地从可配置计算资源共享池中获取所需的资源
	 （例如网络、服务器、存储、应用及服务），资源能够快速供应并释放
	 使管理资源的工作量和与服务提供商的交互减小到最低限度

	 国内运营的公有云服务平台大概有这么几家：
	 亚马逊AWS.. Amazon Web Service [æməzən] -- 亚马逊河
	 微软Azure.. [ˈæʒɚ] -- adj.蔚蓝的，天蓝色的
	 阿里云..

	 大部分云的底层架构是通过虚拟化和分布式来实现的

108.云计算的三种服务、IaaS？SaaS？PaaS？
	IaaS -- Infrastructure-as-a-Service
	IaaS（基础设施即服务）
	SaaS -- Software-as-a-Service
	SaaS（软件即服务）
	PaaS -- Platform-as-a-Service
	PaaS（平台即服务）
	不好理解？没关系，举个简单易懂的例子。甲乙丙三人都是做买卖的，甲种小麦，相当于IaaS提供商、乙卖面粉
	相当于PaaS提供商、丙卖馒头，相当于SaaS提供商

109. VPN是什么？
	 Virtual Private Network -- 虚拟私人网络
	 作用：提供安全可靠的通信渠道，一般而言企业使用较多。延伸作用：科学上网(翻墙)
	 说明：VPN的出现并不是为了“科学上网”，而是在公网上建立加密的通信渠道

	 VPS是什么？
	 Virtual Private Server -- 虚拟专用服务器

110. 什么是SS?
	 SS全称shadowsocks(幽灵短袜)，一开始为个人独立开发并用作“科学上网”
	 后被大家所熟知和广泛使用。再后来，据说作者被请去“喝茶”，停止了该项目
	 什么是socks? sock -- 短袜。这里是防火墙安全会话转换协议
	 socks:Protocol for sessions traversal across firewall securely
	 socks协议提供一个框架，为在TCP和UDP域中的客户机，服务器应用程序能更方便安全地使用网络防火墙所提供的服务
	 协议工作在OSI参考模型的第5层(会话层)
	 socks代理与应用层代理、HTTP层代理不同，socks代理只是简单地传递数据包，而不必关心是何种应用协议（比如FTP、HTTP和NNTP请求）
	 所以，socks代理比其他应用层代理要快得多。它通常绑定在代理服务器的1080端口上
	 浏览网页时常用的代理服务器通常是专门的http代理，它和socks是不同的
	 因此，您能浏览网页不等于您一定可以通过socks访问Internet

111. 什么是SSR?
	 SSR全称shadowsocks-R。SSR作者声称SS不够隐匿，容易被防火墙检测到，SSR改进了混淆和协议
	 更难被防火墙检测到。简单地说，SSR是SS的改进版

112. VPN与SS,SSR的区别
	 SS和SSR两者原理相同，都是基于socks5代理。客户端与服务端没有建立专有通道
	 客户端和实际要访问的服务端之间通过代理服务器进行通信，客户端发送请求和接受服务端返回的数据都要通过代理服务器
	 SSR目的是为了能让流量通过防火墙。客户端请求服务端数据流程（SSR)
	 （1）浏览器发送请求（基于socks5协议）， 通过ssr客户端将sock5协议通过协议插件和混淆插件进行转换加密
	 使得来自客户端的流量和基于HTTP协议的流量无差别
	 （2）SSR服务端（代理服务器）收到请求后，通过混淆插件、协议插件将数据解密并还原协议，最后转发到目标服务器
	 目的（作用）不同，VPN是为了保证通信的安全性、私密性，不是专门为“科学上网”制定的技术
	 而SS/SSR则是为了转发客户端流量，绕过防火墙的检测，从而达到“科学上网”的真实意图
	 但是没有保证数据传输的安全性

113. Guava Cache -- 在内存中缓存数据，相比较于数据库或redis存储，访问内存中的数据会更加高效
	 下面的这几种情况可以考虑使用Guava Cache:
	 1> 愿意消耗一些内存空间来提升速度
	 2> 预料到某些键会被多次查询
	 3> 缓存中存放的数据总量不会超出内存容量

114. 贪心算法的理解 -- 
	 问题：删除一个整数的k个数字，要求得到的值是最小值？
	 步骤：先删除整数的一个数字，得到最小值
	 	   ............
	 	   经历k次，得到最小值

 	 规律：依次求得[局部最优解]，最终求得[全局最优解]的思想，就是贪心算法

115. 栈的数据结构:stack
	 栈是一种特殊的线性表，线性表是数组实现的，那么栈底是数组的头还是尾呢？
	 index = 0的位置是栈底 -- 栈底是数组的头
	 一般定义一个top表示栈顶元素在数组中的位置
	 当栈中有一个元素时，top = 0，所以通常判定空栈的条件就是 top = -1

	 问题：最早进栈的元素是不是只能最后出栈呢？*** 文字游戏
	 不是的，A-push A-pop，B-push B-pop

	 Stack.peek()不改变栈的值(不删除栈顶的值)，Stack.pop()会把栈顶的值删除

116. arthas -- Alibaba开源的针对java问题诊断的工具 
	 Jprofiler -- java性能剖析工具
	 yourKit，JVM profiler等...

117. http -- 状态码502代表什么？
	 一般是网关错误....

118. mysql - binlog:
     binlog是记录所有数据库表结构变更（例如create、alter、table…）
     以及表数据修改（insert、update、delete…）的二进制日志，
     它不会记录select和show之类的操作，多说一句，如果update操作没有造成数据变化，也是会记入binlog

119. 拜占庭将军问题？ 拜占庭 -- 古代东罗马帝国的首都
	 计算机科学家Leslie Lamport(莱斯利.兰伯特)提出的关于网络通信中一致性的问题

	 什么是Raft算法？
	 Raft算法是一种简单易懂的共识算法。它依靠状态机和主从同步的方式，在各个节点之间实现数据的一致性
	 raft两个核心要点: 选取主节点，同步数据，那么怎么样选取主节点呢？
	 raft为节点定义了三种角色:
	 a. Leader(主节点)
	 b. Follower(从节点)
	 c. Candidate(参与投票竞争的节点)

	 共识算法有哪些？
	 Raft -- etcd
	 ZAB -- zookeeper(类似Paxos算法，但是不是Paxos)
	 Paxos -- 谷歌的分布式锁服务Chubby就是以Paxos算法为基础
	 PBFT -- 区块链技术

	 前三个解决的是节点故障问题，而PBFT解决了拜占庭将军问题(节点故意欺骗)

120. mvn compile和mvn package的区别？时间长了容易迷糊
	 一.mvn compile 编译代码，代码生成字节码文件，这一阶段会生成target目录
	 二.mvn package 编译打包，这个命令相比mvn compile会生成jar包文件

121. 长连接的心跳问题
	 心跳的实现分为心跳的发送和心跳的检测，心跳由谁来发都可以，也可以双方都发送，但是检测心跳
	 必须由发起连接的这端进行，才安全。因为只有发起连接的一端检测心跳，知道链路有问题，这时才会去断开连接
	 进行重连，或者重连到另一台服务器

123. sonarQube -- nginx做代理时问题，web静态资源无法访问
	 sonar.properties 里配置  sonar.web.context=/sonar

124. mysql主从复制原理
	 Mysql的Replication是一个异步的复制过程（mysql5.1.7以上版本分为异步复制和半同步两种模式）
	 从一个 Mysql instance(我们称之为 Master)复制到另一个Mysql instance(我们称之 Slave)
	 在Master与Slave 之间的实现整个复制过程主要由三个线程来完成，其中两个线程(Sql线程和IO线程)在Slave端
	 另外一个线程(IO线程)在Master端
	 Slave上面的IO线程连接上Master，并请求从指定日志文件的指定位置(或者从最开始的日志)之后的日志内容
	 Master接收到来自Slave的IO线程的请求后，通过负责复制的IO线程根据请求信息读取指定日志指定位置之后的日志信息
	 返回给Slave端的IO线程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息在Master端的
	 Binary Log文件的名称以及在Binary Log中的位置
	 Slave的IO线程接收到信息后，将接收到的日志内容依次写入到Slave端的Relay Log文件(mysql-relay-bin.xxxxxx)的最末端
	 并将读取到的Master端的bin-log的文件名和位置记录到master- info文件中，以便在下一次读取的时候能够清楚的告诉Master
	 “我需要从某个bin-log的哪个位置开始往后的日志内容，请发给我”
	 Slave的SQL线程检测到Relay Log中新增加了内容后，会马上解析该Log文件中的内容成为在Master端真实执行时候的那些可执行
	 的Query语句，并在自身执行这些Query。这样，实际上就是在Master端和Slave 端执行了同样的Query，所以两端的数据是完全一样的

	 但是有个要求就是二进制日志的格式  -- row -- mysql5.7之后默认的二进制日志格式 

125. java中文件的IO有几种
	 普通IO: FileWriter,InputStream...
	 FileChannel: 存在于java.nio包中
	 MMAP: MappedByteBuffer...

126.怎么理解延迟(latency)和吞吐量(throughput)
	latency -- 延迟测量的是每个应用程序感受到的时间长短
	throughput -- 吞吐量测量的是整个系统的处理效率
	这是两个不同的概念和目标...
	响应时间(RT)

	为什么要分别考量？就是个rt问题，一条马路，2个车道，并发最高就只能为2。但是吞吐量呢，表示一段时间内通过的车辆数
	如果2个车道都被堵住了，rt很大，那么并发为2，吞吐量为0；如果没有堵车，通过很快，rt很低，吞吐量就很高
	所以，还是看rt

127. 什么是人工智能(Artificial Intelligence)
	 人工智能的分级:
	 	ANI -- Artificial Narrow Intelligence 弱人工智能
	 	AGI -- Artificial General Intelligence 强人工智能
	 	ASI -- Artificial Super Intelligence 超人工智能

128. 大数据的3v指的是什么？
	 大数据的三个特点: 大(数据量大) 繁(多样性) 快(处理过程高效)
	 volume,variety,velocity === 3v

129. 经常说架构师，用英文怎么说？  architect [ˈɑ:rkɪtekt] -- 建造师，设计师

130. 那些大公司的代码不愿意开放的更重要的原因是代码写得太烂了，一旦开源，就没人敢用他们的产品了

131. linux的 grep -w 命令不是万能的，molto-ms-gateway-dev.jar  gateway-dev.jar
	 grep -w "gateway-dev.jar"，会把两个进程都查出来

132. 如何修改jvm堆内存?
	 JVM初始分配的堆内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的堆内存由-Xmx指定，默认是物理内存的1/4
	 默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制；
	 空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx 相等以避免在每次GC后调整堆的大小。
	 说明：如果-Xmx 不指定或者指定偏小，应用可能会导致java.lang.OutOfMemory错误，此错误来自JVM
	 不是Throwable的，无法用try...catch捕捉

	 那么怎么查看jvm的参数设置呢？

133. 16进制的前缀是0x，数字零和英文字母X(注意：0x中的0是数字0，而不是字母O)
	 整数和浮点数在计算机内部存储的方式是不同的，整数运算永远是精确的(除法难道也是精确的?是的!)

134. 要让Python程序实现多进程(multiprocessing),我们先了解操作系统的相关知识
	 Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次
     但是fork()调用一次，返回两次，因为操作系统自动把当前进程(称为父进程)复制了一份(称为子进程)然后
	 分别在父进程和子进程内返回,子进程永远返回0，而父进程返回子进程的ID。这样做的理由是
	 一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID
	 而子进程只需要调用getppid()就可以拿到父进程的ID

135. 常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出一个子进程来处理新的http请求
	 Tomcat是这样的吗？tomcat是多线程，有自己的线程池，可以配置，默认应该是150个，理论上并发数就是150

136. Base64编码算法: 是什么?
	 Base64是一种用64个字符来表示任意二进制数据的方法，是一种二进制编码方法，是一种查表的编码方法
	 不能用于加密，64个字符分别是:[a-z,A-Z,0-9,+,/]，26个英文字母... 刚好64个

137. 电子邮件软件被称为MUA -- Mail user Agent(邮件用户代理)
	 Email从MUA发出去，不是到达收件人的电脑，而是先到达MTA -- Mail Transfer Agent(邮件传输代理)
	 就是所谓的邮件服务提供商(网易啊，新浪啊等等)。还有一个概念MDA -- Mail Delivery Agent(邮件投递代理)
	 一封邮件从发到收的过程如下:
	 user -> MUA -> MTA ... MTA -> MDA <- MUS <- user
	 发送邮件的协议: SMTP -- Simple mail transfer protocol
	 收邮件的协议: POP -- Post office protocol  IMAP -- Internet message access protocol

138. 数据库(database) -- 两个关键的作用, 存储和查询, 存储是一方面, 查询是一方面



140. JavaScript是一种单线程的脚本语言
	 这跟历史有关系。JavaScript从诞生起就是单线程。
	 原因大概是不想让浏览器变得太复杂，因为多线程需要共享资源且有可能修改彼此的运行结果
	 对于一种网页脚本语言来说，这就太复杂了。后来就约定俗成，JavaScript为一种单线程语言

141. 正则表示式，默认是贪婪匹配，但是特别注意"？"，带？的正则一般都是非贪婪匹配

142. 微信公众号: 
	 订阅号 -- 会折叠在订阅号里的文件夹内，打开看里面的订阅号
	 服务号 -- 单独展示在微信的首页，和好友的栏位同级别

	 关注服务号才能完成 -- 第三方登录

	 
143.java中与或非运算规则事例，有如下两个二进制数据:
	7 -- 0111.........9 -- 1001   

	java中、与运算(符号&) 、都为1时，则为1，否则都是0
	7&9  === > 0001 --> 1
	java中、或运算(符号|) 、有一个为1，则为1，两个都是0，则为0
	7|9  === > 1111 --> 15
	java中、异或运算(符号^) 、不同为1，同则为0
	7^9  === > 1110 --> 14

	java中、取反运算(符号~) : 按位取反
	所谓原码就是二进制定点表示法，即最高位为符号位，“0”表示正，“1”表示负，其余位表示数值的大小
	二进制数在内存中是以补码的形式存放的；补码首位是符号位，0表示此数为正数，1表示此数为负数
	正数的补码、反码都是其二进制本身
	举个例子：1的二进制表示为： --- 00000000000000000000000000000001  -- 第一位0表示正数
			 -1的二进制表示为： --- 11111111111111111111111111111111  -- 第一位1表示负数
	两者的关系是怎么来的
		--> 1的二进制反码表示为：11111111111111111111111111111110
		--> 反码再 + 1得到补码为：11111111111111111111111111111111
	负数的二进制计算规律：
	1、取负数的绝对值的原码
	2、计算原码的反码(对原码取反)
	3、对反码加一，获取补码



	 补码解决了原码中0存在两种编码的问题：
	 0=[00000000]原=[10000000]原

	 补码[10000001]补 表示−128；此外，原码中还存在加法错误的问题：
	 1+(−1)=[00000001]原+[10000001]原=[10000010]原=−2

	 若用补码，则可得到正确结果：
	 1+(−1)=[00000001]补+[11111111]补=[00000000]补=0

	 ...因此，在计算机存储整数时，采用的是补码

144. java中有两种情况，finally语句是不会执行到的
	 1. try...catch..finally块压根就没执行到，finally语句是不会被执行的
	 2. try块中有语句System.exit(0)，这是终止jvm执行，当然finally语句也不会被执行到

145. Spring Cloud Stream -- 是什么？
	 简单的说: Spring Cloud Stream本质上就是整合了Spring Boot和Spring Integration
	 实现了一套轻量级的消息驱动的微服务框架。通过使用Spring Cloud Stream，可以有效地简化开发人员对消息
	 中间件的使用复杂度，让系统开发人员可以有更多的精力关注于核心业务逻辑的处理
	 目前只支持两个著名消息中间件的自动化配置:
	 	rabbitmq && kafka

146. VS Code提供了两种设置方式: 
     用户设置:这种方式进行的设置，会应用于该用户打开的所有工程 
     工作空间设置：工作空间是指使用VSCode打开的某个文件夹，在该文件夹下会创建一个名为.vscode的隐藏文件夹
	 里面包含着**仅适用于当前目录的**VS Code的设置
     --工作空间的设置会覆盖用户的设置

147. zookeeper和eureka那个更好使？
	 CAP理念：它的意思是，一个分布式系统不能同时满足一致性，可用性，分区容错性
	 Consistency -- 数据一致性，数据需要同步
	 Availability -- 可用性，任何时候请求都要在规定的时间内收到响应
	 Partition Tolerance -- 分区容错性，当网络通信发生故障时，保证集群依然可用，不能因为某个节点挂掉而影响整个系统的正常工作
	 对于分布式系统来说，出现网络分区是不可避免的，partition-tolerance是必须的，是个客观存在的事实，不可避免，也无法绕过

	 zookeeper -- 侧重CP原则，但数据不是强一致性的，过半数节点操作成功就可以返回
	 	可以先和master节点同步数据，再读取数据，保证数据的强一致性
		如果master节点挂掉，选举master节点期间，整个zookeeper集群是不可用的，达不到A的标准

	 eureka -- 侧重AP原则，eureka各个节点是平等的，某个节点挂掉不会影响其他正常节点，正常的节点依然可以提供注册和查询服务
	 	当客户端向eureka注册时发现连接失败，则会自动切换至其他节点

148. 分布式和集群
	 分布式 -- 一个业务分拆成多个子业务，分别部署在不同的服务器上
	 集群 -- 同一个业务，分别部署在不同的服务器上

149. 队列 -- queue
	 front -- 队列头（前端）, rear -- 队列尾（后端）
	 明白与否: 看定义规则，只允许在前端--front删除元素，只允许在后端(rear)插入元素
	 初始化的时候，队尾指针和队头指针都指向头结点，索引值都是0
	 每次插入一个元素rear指针增加1，每次删除一个元素front指针增加1，所以rear=front则说明是空队列

150. 数据库创建索引原则
	 一.适合索引的列是出现在where子句中的列，或是连接子句中的列
	 二.基数较小的列，索引效果较差，没必要在此列建立索引
	 	这里的基数怎么理解？在一张表的一个列中、相同的值较少，不同的值较多，可以说是基数较大
	 三.使用短索引，如果对长字符串列建立索引，应该指定一个前缀长度，这样能节省大量索引空间
	 四.不要过度索引，索引需要额外的磁盘空间，并降低写操作的性能，在更新表内容的时候
	 	索引会更新甚至重构，索引列越多，这个时间就会越长

151. 索引优化 -- 两个至关重要的概念
	 基数--单个列唯一键的数量叫做基数
	 回表--当对一个列创建索引之后，索引会包含该列的键值及键值对应行所在的rowid
	 通过索引中记录的rowid访问表中的数据就叫回表。回表次数太多会严重影响SQL性能
	 如果回表次数太多，就不应该走索引扫描，应该直接走全表扫描？有道理？

	 如果MySQL估计使用索引比全表扫描还慢，则不会使用索引。返回数据的比例是重要的指标，比例越低越容易命中索引
	 记住这个范围值——30%，后面所讲的内容都是建立在返回数据的比例在30%以内的基础上。反思一个问题，在有些情况下使用索引
	 比全表扫描速度还慢。所以mysql才会预估，返回数据所占的比例就是预估的一个指标，这种预估是人为干预不了的
	 前导模糊查询不能命中索引
	 数据类型出现隐式转换的时候不会命中索引
	 union、in、or都能够命中索引，建议使用in
	 左前缀原则，复合索引的情况下，查询条件不包含索引列最左边部分（不满足最左原则），不会命中复合索引

152. java中POJO -- plain old java object -- 简单java对象，普通javaBean，平淡无奇的java对象

153. 什么是类的加载？
	 类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，
	 然后在堆区创建一个 java.lang.Class对象，用来封装类在方法区内的数据结构，类的加载的最终产品是位于堆区中的Class对象
	 Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口

	 java语言中，类型的加载，连接，初始化过程都是在程序运行期间完成的
	 类的生命周期，加载、验证、准备、解析、初始化、使用、卸载 -- 七个阶段
	 其中验证、准备、解析统一称为连接

	 通过子类引用父类的静态字段，不会导致子类初始化。对于静态字段，只有直接定义这个字段的类才会被初始化

	 常量在编译阶段会存入到调用类的常量池中，本质上并没有引用到定义常量的类，因此不会触发定义常量类的初始化
	 这里的常量是指被static final修饰的

155. 类加载准备阶段，为类变量(static)分配内存，并将其初始化为默认值，这些内存都将在方法区中分配
	 这里注意: 类变量会在对象实例化时随着对象一块分配在Java堆中
	 		  这里的默认值不是在Java代码中被显式地赋予的值，而是数据类型的默认值
              被final修饰的变量，系统不会为其赋默认值，必须显式的赋值，在变量声明时或是在类初始化时
			  被static和final共同修饰的变量，必须在声明时显式的赋值
	 example: public static int a = 3,准备阶段被赋值为a=0
	  		  public static final int a = 3,准备阶段被赋值为a=3(实现--ConstantValue属性)

156. 类加载解析阶段，把类中的符号引用转换为直接引用
	 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、
	 方法句柄和调用点限定符7类符号引用进行
	 符号引用就是一组符号来描述目标，可以是任何字面量。
	 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄

157. jvm类加载机制
	 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入
	 除非显式使用另外一个类加载器来载入

     父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类
	 同时可见性和单一性也是类加载器的机制，子类可以看见父类加载器加载的所有类，而父类加载器看不见子类加载器所
	 加载的类。并且一个类仅加载一次
     
	 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时
	 类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据
	 并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效

	 双亲委派机制：
	 jvm创建的三类类加载器，什么是类加载器？
	 类加载器就是一个用来加载类文件的类

	 Bootstrap-ClassLoader(引导类)启动类加载器 -- 加载java的核心类库(jre/lib/rt.jar)，是用原生c++代码实现的
	 并不继承自java.lang.ClassLoader，所以调用 String.class.getClassLoader ==> 返回null
	 加载扩展类和应用类加载器，并指定他们的父类加载器，在java中获取不到

	 Extension-ClassLoader 扩展类加载器
	 它用来加载 Java 的扩展库(jre/ext/*.jar)

	 App-ClassLoader 应用类加载器或是系统类加载器
	 它根据Java应用的类路径（CLASSPATH）来加载Java类，一般来说，Java 应用的类都是由它来完成加载的
	 可以通过 ClassLoader.getSystemClassLoader()来获取它
	
	 此外，每个应用还可以自定义ClassLoader，通过继承 java.lang.ClassLoader类的方式实现自定义类加载器

	 总结 -- 可以看出ClassLoader类是由AppClassLoader加载的
	 他的父亲是ExtClassLoader，ExtClassLoader的父亲无法获取是因为它是用C++实现的，即启动类加载器!

	 ClassLoader的双亲委派机制：
	 应用类加载器的双亲为扩展类加载器，扩展类加载器的双亲为启动类加载器，其优点是：
	 保证java核心库的安全性，如果用户自己写了一个java.lang.String类就会因为双亲委派机制不能被加载
	 不会破坏原生的String类的加载
	 
	 弊端 --- 无法解决的一个问题
	 判断类是否加载的时候,应用类加载器会顺着双亲路径往上判断,直到启动类加载器
	 但是启动类加载器不会往下询问,这个委托路线是单向的,即顶层的类加载器,无法访问底层的类加载器所加载的类
	 前面提到的类加载器的代理模式并不能解决Java应用开发中会遇到的类加载器的全部问题
	 Java提供了很多服务提供者接口（Service Provider Interface，SPI），允许第三方为这些接口提供实现
	 常见的SPI有JDBC、JCE、JNDI、JAXP和JBI等，这些SPI的接口由Java核心库来提供
	 而这些SPI的实现代码很可能是作为Java应用所依赖的jar包被包含进来，可以通过类路径（CLASSPATH）来找到
	 SPI接口中的代码经常需要加载具体的实现类
	 而问题在于，SPI的接口是Java核心库的一部分，是由引导类加载器来加载的
	 SPI实现的Java类一般是由系统类加载器来加载的。引导类加载器是无法找到SPI的实现类的
	 因为它只加载Java的核心库。它也不能代理给系统类加载器，因为它是系统类加载器的祖先类加载器
	 也就是说，类加载器的代理模式无法解决这个问题

158. jvm组成
	 JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，
	 而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间
	 默认情况下年轻代按照8:1:1的比例来分配
	 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，
	 方法区还有一个别名Non-Heap(非堆)，栈又分为java虚拟机栈和本地方法栈主要用于方法的执行

159. 查看jvm使用的那种garbage-collection
	 win + cmd -- command： java -XX:+PrintCommandLineFlags -version
	 参数控制： -XX:+UseSerialGC 串行收集器
	 		   -XX:+UseParNewGC ParNew收集器
					-XX:ParallelGCThreads 限制线程数量
			   -XX:+UseParallelGC 使用Parallel收集器+老年代串行
			   -XX:+UseParallelOldGC 使用Parallel收集器+老年代并行
			   -XX:+UseConcMarkSweepGC 使用CMS收集器
					-XX:+UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理，整理过程是独占的，会引起停顿时间变长
					-XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理
					-XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量）
			   -XX:+UnlockExperimentalVMOptions -XX:+UseG1GC 
			   	    -XX:MaxGCPauseMillis=50 #暂停时间目标； 
					-XX:GCPauseIntervalMillis=200 #暂停间隔目标； 
					-XX:+G1YoungGenSize=512m #年轻代大小； 
					-XX:SurvivorRatio=6 #幸存区比例

160. 常见的几种garbage-collection
	 serial-收集器
	 parallel-收集器
	 CMS-收集器
	 G1-收集器

161. sun-jdk监控和故障处理命令
	 jps -- jvm process status tool -- 显示系统的HotSpot虚拟机进程 -- java进程状态工具
	 	options:
		-l -- 输出主类全名或jar路径
		-v -- 输出jvm启动时显式指定的jvm参数
		-m -- 输出jvm启动时传递给main函数的参数
		-q -- 只输出lvmid()
	 jstat -- jvm statistics monitoring -- 监视虚拟机运行时状态信息 -- java进程统计工具
	 	jstat -options pid 
		options:
		-class -- 监视类装载、卸载数量、总空间以及耗费的时间
		-compiler -- 输出JIT编译过的方法数量耗时等
		-gc -- 垃圾回收堆的行为统计
			example: jstat -gc 12342 2000 20 -- 每隔2000ms输出12342的gc情况，一共输出20次 
			show-datas----------
			C即Capacity-总容量，U即Used-已使用的容量
			S0C:survivor0区的总容量
			S0U:survivor0区已使用的容量
			PC:当前perm的容量 (KB)
			PU:perm的使用 (KB)
			YGC:新生代垃圾回收次数
			YGCT:新生代垃圾回收时间
			FGC:老年代垃圾回收次数
			FGCT:老年代垃圾回收时间
			GCT:垃圾回收总消耗时间
		-gccapacity === 功能同 -gc
		-gcutil === 功能同 -gc，只不过输出的是百分比
		.....
		总的来说，选项不少，大同小异


	 HSDB就是HotSpot Debugger的简称 -- jhsdb命令
	 jhsdb是Java9引入的，所以在java9的环境中才能使用该命令
	 jhsdb有clhsdb、debugd、hsdb、jstack、jmap、jinfo、jsnap这些mode可以使用
		jhsdb jmap --help 
		example -- jhsdb jmap --heap --pid 12342
		jmap -- jvm memory map -- 用于生成heap dump文件，如果不使用这个命令
			还可以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候自动生成dump文件
			jmap不仅能生成dump文件，还可以查询finalize执行队列、Java堆和永久代的详细信息：
			如当前使用率、当前使用的是哪种收集器等
			options:
			-dump -- 生成对文件转储快照
				jmap -dump:live,format=b,file=dump.hprof 12432
				dump堆到文件,format指定输出格式，live指明是活着的对象,file指定文件名
				dump.hprof这个后缀是为了后续可以直接用MAT(Memory Anlysis Tool)打开
				有时候 jmap -dump:live 不能使用，请去掉live参数
				jmap -dump:format=b,file=dump.hprof 12432
			-finalizerinfo -- 打印等待回收对象的信息
			-heap -- 打印heap的概要信息，GC使用的算法，heap的配置及wise heap的使用情况
				可以用此来判断内存目前的使用情况以及垃圾回收情况
		example -- jhsdb jinfo --flags --pid 12342
		jinfo -- JVM Configuration info -- 这个命令作用是实时查看和调整虚拟机运行参数 
			之前的jps -v命令只能查看到显式指定的参数，如果想要查看未被显式指定的参数的值就要使用jinfo命令
			options:
			-flag : 输出指定args参数的值
			-flags : 不需要args参数，输出所有JVM参数的值
			-sysprops : 输出系统属性，等同于System.getProperties()

	javap -- jdk自带的反解析工具
		-Test.class -- 一个编译过的类文件,想看一下详细的编译信息
		-javap -c Test.class

162. java编译器和jvm编译器
	 java编译器 *.java -->*.class
	 jvm编译器  字节码 -->机器码
	 这是两种编译情况，区分开来
	 相同程序在64位JDK上消耗的内存一般比32位JDk上要大，这是由于指针膨胀以及数据类型对齐补白等因素造成的
	 现阶段64位JDK的性能测试结果普遍低于32位JDK

163. jvm的三种GC
	 MinorGC -- 针对年轻代(包括Eden和Survivor区)
	 FullGC -- 针对整个堆的垃圾回收
	 System.gc(),其实这个gc()函数的作用只是提醒虚拟机
	 程序员希望进行一次垃圾回收。但是它不能保证垃圾回收一定会进行
	 而且具体什么时候进行是取决于具体的虚拟机的，不同的虚拟机有不同的对策
	 stack的内存管理是顺序分配的，而且定长，不存在内存回收问题、知道的垃圾检测方法
	 引用计数法：有引用计数+1，引用失效计数-1、问题：如果a,b两个对象互相引用，计数永远不为0，导致无法回收..
	 可达性分析算法：以根集对象为起点进行搜索，如果有对象不可达，就是垃圾对象

	 垃圾回收算法：分代回收算法..sun 公司的JDK使用的虚拟机都是HotSpot，主要关注的是堆内存
	 这里的分代回收指的也是对堆内存的回收。分代收集分为：年轻代（young Generation），老年代(old Generation)
	 注：永久代jdk1.6取消了，放入了方法区

	 年轻代垃圾回收Minor{未成年的}GC -- 对象的生命周期很短，分为三个区域：Eden和两个存活区servivor0和survivor1
	 分别占内存80%-10%-10%，使用的是 停止-复制(stop-and-copy)清理法，当Eden区满时，就就执行一次Minor GC
	 将剩余的对象都添加到survivor0中。Eden是连续的空间，且survivor区总有一个为空
	 停止-复制清理法就是将Eden区和一个survivor中还存活的对象复制到另一个survivor区中，这里的停止的意思是
	 在回收内存时，需要暂停其他所有线程的执行。默认15次清理之后还存活的直接放入老年代中
	 新生消亡...对象从这Eden区域消失的过程、我们称之为MinorGC，每次MinorGC会触发Stop-The-World

	 老年代存放较大的实例化的对象和在年轻代中存活足够久的对象。用的是标记-整理算法，即标记存活的对象向一端移动
	 保证内存的完整性，然后将未标记的清理掉。当老年代不够用时，也会执行Major GC,即Full GC

	 方法区中也是存在垃圾回收的，比如回收无用的类和废弃的常量等。年轻代的GC是必须的，而老年代的GC不是必须的
	 可以通过参数的配置



164. 使用jdk自带工具对项目进行监控和分析 -- jconsole && jvisualvm 
	 添加如下启动参数: -- 两者都是基于jmx，jmx的默认端口1099
	 	nohup java -jar pixel-common-dev.jar
		-Djava.rmi.server.hostname=47.94.100.10
		-Dcom.sun.management.jmxremote
		-Dcom.sun.management.jmxremote.port=1099
		-Dcom.sun.management.jmxremote.authenticate=false
		-Dcom.sun.management.jmxremote.ssl=false

	这里的jmx是什么？
	所谓JMX，是Java Management Extensions(Java管理扩展)的缩写，是一个为应用程序植入管理功能的框架
	用户可以在任何Java应用程序中使用这些代理和服务实现管理

165. jdk1.8默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）
	 jdk1.9默认垃圾收集器Garbage-First (G1)

166.java8新特性
	1. lambda表达式和函数式接口
	2. 接口的默认方法和静态方法
	3. 方法引用
	4. 重复注解
	5. 全新的Date-Time API

	Lambda表达式
	lambda表达式允许把一个函数作为参数传递进方法中
	Arrays.asList("a","b","c").forEach( obj->System.out.print(obj) );
	这里obj的类型是编译器推测出来的，当然也可以显式的指定
	Arrays.asList("a","b","c").forEach( (String obj) ->System.out.print(obj) );
	函数体可以放在一对花括号中
	Arrays.asList( "a", "b", "d" ).forEach( e -> {
	System.out.print( e );
	System.out.print( e );
	} );
	可以有返回值,返回值类型也是编译器推测出来的，一行代码的话没必要显式return
	可以引用类的成员变量和局部变量，如果这些变量不是final修饰的话，会被隐式转化成final，这样效率更高下面是等价的
	String separator = ",";
	Arrays.asList( "a", "b", "d" ).forEach( 
	( String e ) -> System.out.print( e + separator ) );

	final String separator = ",";
	Arrays.asList( "a", "b", "d" ).forEach( 
	( String e ) -> System.out.print( e + separator ) );

	functional接口（函数式接口）--可被隐式的转化成lambda表达式，函数式接口就是具有一个方法的普通接口
	注意一个方法。这里记住默认方法和静态方法并不影响函数式接口的契约，可随意使用
	@FunctionalInterface
	public interface Test{
		void method();
	   default void defaultMethod(){
		......
	   }
	}
	@FunctionalInterface注解不是必须的，只要接口只包含一个抽象方法，虚拟机会自动判断该接口为函数式接口

	接口的默认方法和静态方法：
	默认方法与抽象方法不同之处在于抽象方法必须要求实现，但是默认方法则没有这个要求。相反
	接口都如果提供一个所谓的默认实现，这样所有的接口实现者将会默认继承它（如果有必要的话，可以覆盖这个默认实现）

	private interface Defaulable {
		// Interfaces now allow default methods, the implementer may or 
		// may not implement (override) them.
		default String notRequired() { 
		return "Default implementation"; 
		}        
	}
	 
	private static class DefaultableImpl implements Defaulable {
	}

	private static class OverridableImpl implements Defaulable {
		@Override
		public String notRequired() {
		return "Overridden implementation";
		}
	}
	接口中可以声明静态方法（并且可以提供实现）

	全新的Date --Time API 位于 java.Time报下

	5.方法引用：:: - 关于方法引用请关注item-61
	对象::实例方法
	类::静态方法
	类::实例方���
	类::new

167. 算法中有关二分查找的问题，有趣的一个发现，迷惑人的障眼法
	 int mid = (left + right)/2  ==== int mid = left + (right - left)/2

168. 复杂度分析 -- so easy?
	 复杂度描述了什么？
	 复杂度描述的是算法执行时间(或占用空间)，与数据规模的增长关系

	 什么是加权平均值：加权平均值即将各数值乘以相应的权数，然后加总求和得到总体值，再除以总的单位数

	 时间复杂度:算法的「执行时间」与每行代码的「执行次数」成正比T(n) = O(f(n))
	 其中T(n)表示算法执行总时间，f(n)表示每行代码执行总次数，而n往往表示数据的规模
		对数阶时间复杂度: 最难分析的一种时间复杂度 O(logn) | O(nlogn)
		不管是以2为底、以3为底，还是以10为底，可以把所有对数阶的时间复杂度都记为O(logn),因为对数之间可以转换的
		随着n(数据规模)的增长，T(n)逐渐增长率:
		O(n*n) > O(nlogn) > O(n) > O(logn)

	 空间复杂度:表示算法的「存储空间」与「数据规模」之间的增长关系
	 	常见的空间复杂度: O(1) O(n) O(n*n)

169. B+Tree索引相关了解
	 B+树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是B+树的高度
	 数据库中的B+树索引可以分为聚集索引（clustered index）和辅助索引（secondary index）
	 它们之间的最大区别就是，聚集索引中存放着一条行记录的全部信息
	 而辅助索引中只包含索引列和一个用于查找对应行记录的『书签』
	 所有正常的表应该有且仅有一个聚集索引，绝大多数情况下都是主键
	 表中的所有行记录数据都是按照聚集索引的顺序存放的
	 innodb引擎中，数据表有且仅有一个聚集索引

170. 锁相关了解
	 OCC - 乐观锁、PCC - 悲观锁
	 乐观锁和悲观锁在本质上并不是同一种东西，一个是一种思想，另一个是一种真正的锁，但是它们都是一种并发控制机制
	 乐观锁是一种思想，它其实并不是一种真正的『锁』，它会先尝试对资源进行修改，在写回时判断资源是否进行了改变，
	 如果没有发生改变就会写回，否则就会进行重试，在整个的执行过程中其实都没有对数据库进行加锁；

	 悲观锁就是一种真正的锁了，它会在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源
	 其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后
	 其他线程才能重新操作资源

	 InnoDB实现了标准的行级锁，也就是共享锁(Shared Lock)和互斥锁(Exclusive Lock)
	 共享锁和互斥锁的作用其实非常好理解：
	 共享锁（读锁）：允许事务对一条行数据进行读取；
	 互斥锁（写锁）：允许事务对一条行数据进行删除或更新；
	 而它们的名字也暗示着各自的另外一个特性，共享锁之间是兼容的，而互斥锁与其他任意锁都不兼容

	 因为共享锁代表了读操作、互斥锁代表了写操作，所以我们可以在数据库中并行读，但是只能串行写
	 只有这样才能保证不会发生线程竞争，实现线程安全

	 无论是共享锁还是互斥锁其实都只是对某一个数据行进行加锁，InnoDB支持多种粒度的锁，也就是行锁和表锁
	 为了支持多粒度锁定，InnoDB存储引擎引入了意向锁(Intention Lock)，意向锁就是一种表级锁，同样也分为
	 意向共享锁，意向互斥锁

	 对于mysql数据库，默认情况下，数据库处于自动提交模式。每一条语句处于一个单独的事务中，在这条语句执行完毕时
	 如果执行成功则隐式的提交事务，如果执行失败则隐式的回滚事务
	 对于正常的事务管理，是一组相关的操作处于一个事务之中，因此必须关闭数据库的自动提交模式
     查看是否自动提交命令，autocommit = 1表示开启自动提交，autocommit = 0表示关闭自动提交
	 Command：select @@autocommit;
	 		  show variables like 'autocommit';
	 如果结合Spring来获取数据库连接，就不用担心，spring会将底层连接的自动提交特性设置为false

171. 一些算法技巧之---巧用双指针：在处理单链表的时候非常有用
	 1.判断单链表是否有环：设置一个慢指针和一个快指针来遍历这个链表
	   慢指针一次移动一个节点，而快指针一次移动两个节点，如果该链表没有环，则快指针会先遍历完这个表
	   如果有环，则快指针会在第二次遍历时和慢指针相遇
	 2.一次遍历找到链表中间位置节点：设置一个快指针和慢指针。慢的一次移动一个节点，而快的两个。在遍历链表的时候
	   当快指针遍历完成时，慢指针刚好达到中点
	 3.单链表中倒数第k个节点：设置两个指针，其中一个指针先移动k个节点。之后两个指针以相同速度移动
	   当那个先移动的指针遍历完成的时候，第二个指针正好处于倒数第k个节点
	

173. 排序的稳定性怎么理解？
	 稳定的排序算法，相等的数排完序之后，其顺序保持不变，对于非稳定排序来说，那就不一定了
	 稳定的排序算法：冒泡排序，归并排序，插入排序
	 非稳定的排序算法：选择排序，快速排序，希尔排序等
	 既然最后排完序之后都是有序的序列，为什么要分稳定排序和非稳定排序呢？
	 其实就是有两个排序关键字的时候，稳定排序可以让第一个关键字排序的结果服务于第二个关键字排序中数值相等的那些数
	 Example: 一个班级的学生开始是按照学号来排序的，现在要按照身高来排序
	 		  稳定排序的话，身高相同的学生，还是按照学号来排序的

174. 搜索算法的一些名词解释
	 场景：走迷宫，从左上角走到右下角，每个点都可以按照右下左上的方向来进行尝试，如果是墙壁，就换一个方向，如果可以走
	 就往前走到下一点，然后再接着尝试。之后的步骤，不在搜索一下明显不对的方向，这就叫做‘剪枝’，剪掉没用的分支，提高效率
	 当然，这样有时候会走到死胡同里去，这就需要‘回溯’，退回到上一步，找到之前有可能出现岔道口的方向
	 再去下一个方向进行搜索。有‘剪枝’和‘回溯’的过程，才能称得上一个完整的搜索算法

175. java基础，短路运算符
	 关键点：不管短路运算符还是非短路运算符，终极目的都是为了求真 -- true
	 看下面的定义：
	 如果 "&&" 运算符的第一个表达式为false,则第二个表达式就不会执行
	 换言之 -- 如果第一个表达式为true,则会执行第二个表达式
	 如果 "||" 运算符的第一个表达式为true,则第二个表达式就不会执行
	 换言之 -- 如果第一个表达式为false,则会执行第二个表达式

176. sychronized同步代码块实现
	 同步代码块是使用monitorenter和monitorexit指令实现的
	 JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。
	 任何对象都有一个monitor与之相关联，当且一个monitor被持有之后，他将处于锁定状态
	 Java中每一个对象都可以作为锁，这是synchronized实现同步的基础：
	 与一切皆对象一样，所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质
	 因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁

	 普通同步方法，锁是当前实例对象
	 静态同步方法，锁是当前类的class对象
	 同步方法块，锁是括号里面的对象

177. java中数组是什么数据类型？引用类型？基本类型？
	 答案 --- java中只有8中基本类型，数组是引用类型
	 八种基本类型：byte、char、short、boolean、int、float、long、double
	 private修饰的方法，只有在类内可以访问？
	 答案 --- private修饰的方法，只有在类内可以访问

178. 内存的存储单元采用了随机读取存储器(RAM， Random Access Memory)
	 所谓的“随机读取”，是指存储器的读取时间和数据所在位置无关，随机读取的特性是内存成为主存储器的关键因素
	 反例：比如磁带，第一首歌可以直接听，但中间的歌曲需要快进才能听
	 我们已经知道，进程需要调用内存中不同位置的数据。如果数据读取时间和位置相关的话，计算机就很难把控进程的运行时间

179. AQS -- AbstractQueuedSychronizer(队列同步器)，是用来构建锁或者其他同步组件的基础框架
     它使用了一个volatile修饰的变量state来维护同步的状态，通过内置的FIFO队列来完成资源获取线程的排队工作
	 如果某个线程对state变量做了改动，则表示该线程获得或者释放了锁，而修改state变量是基于cas操作的，是安全的
	 而且获取锁的方式是非常灵活的，支持超时，可中断方式获取锁。如果想使用该同步器，只需继承 
	 AbstractQueuedSynchronizer即可，至于用户想实现什么样的获取，释放锁逻辑，用户可以自己去定制

180. 多线程设计中有三个同步工具需要我们掌握
	 Semaphore -- 信号量
	 CountDownLatch -- 倒计数门闸锁
	 CyclicBarrier -- 可重用栅栏

181.动态规划(Dynamic Programming)
	动态规划其实和分治策略是类似的，也是将一个原问题分解为若干个规模较小的子问题，递归的求解这些子问题
	然后合并子问题的解得到原问题的解 
	区别在于这些子问题会有重叠，一个子问题在求解后，可能会再次求解，于是我们想到将这些子问题的解存储起来
	当下次再次求解这个子问题时，直接拿过来就是 
	其实就是说，动态规划所解决的问题是分治策略所解决问题的一个子集，只是这个子集更适合用动态规划来解决从而得到
	更小的运行时间，即用动态规划能解决的问题分治策略肯定能解决，只是运行时间长了，因此，分治策略一般用来解决子
	问题相互对立的问题，称为标准分治，而动态规划用来解决子问题重叠的问题
	example:
	动态规划是一种解决问题的方法，并非是一种算法。经典的01背包问题就是一个例子，什么是01背包问题？有一个包和n个物品
	包的容量为m，每个物品都有各自的体积和价值，问当从这n个物品中选择多个物品放在包里而物品体积总数不超过包的容量m时
	能够得到的最大价值是多少？
	(对于每个物品不可以取多次，最多只能取一次，之所以叫做01背包，0表示不取，1表示取)

	动态规划算法是通过拆分问题，定义问题状态和状态之间的关系，使得问题能够以递推（或者说分治）的方式去解决
	在学习动态规划之前需要明确掌握几个重要概念
		阶段、对于一个完整的问题过程，适当的切分为若干个相互联系的子问题，每次在求解一个子问题时对应一个阶段
		     整个问题的求解转化为按照阶段次序去求解
		状态、状态表示每个阶段开始时所处的客观条件，即在求解子问题时的已知条件。状态描述了研究的问题过程中的状况
		决策、决策表示当求解过程处于某一阶段的某一状态时，可以根据当前条件作出不同的选择，从而确定下一个阶段的状态
			 这种选择称为决策
		策略、由所有阶段的决策组成的决策序列称为全过程策略，简称策略
		最优策略、在所有的策略中，找到代价最小，性能最优的策略，此策略称为最优策略
		状态转移方程、状态转移方程是确定两个相邻阶段状态的演变过程，描述了状态之间是如何演变的

	动态规划使用场景
	能采用动态规划求解的问题的一般要具有3个性质
	最优化、如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理
		   子问题的局部最优将导致整个问题的全局最优。换句话说，就是问题的一个最优解中一定包含子问题的一个最优解
	无后效性、即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态
			 只与当前状态有关，与其他阶段的状态无关，特别是与未发生的阶段的状态无关
	重叠子问题、即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到
			  （该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势）
	
	动态规划流程
	划分阶段：按照问题的时间或者空间特征将问题划分为若干个阶段
	确定状态以及状态变量：将问题的不同阶段时期的不同状态描述出来
	确定决策并写出状态转移方程：根据相邻两个阶段的各个状态之间的关系确定决策
	寻找边界条件：一般而言，状态转移方程是递推式，必须有一个递推的边界条件
	设计程序，解决问题

183. InnoDB中的锁分类
	 两个标准的行级锁
	 S - 共享锁 -- 可以理解为读锁 - 其他事物可以继续加共享锁，但是不能继续加排他锁
	 X - 排它锁 -- 可以理解为写锁 - 一旦加了写锁之后，其他事物就不能加锁了
	 
	 兼容性:是指事务A获得一个某行某种锁之后，事务B同样的在这个行上尝试获取某种锁
	 如果能立即获取，则称锁兼容，反之叫冲突。

	 意向锁在InnoDB中是表级锁,和他的名字一样他是用来表达一个事务想要获取什么。意向锁分为:
	 意向共享锁:表达一个事务想要获取一张表中某几行的共享锁。
	 意向排他锁:表达一个事务想要获取一张表中某几行的排他锁。
	 这个锁有什么用呢？为什么需要这个锁呢？ 首先说一下如果没有这个锁，如果要给这个表加上表锁
	 一般的做法是去遍历每一行看看他是否有行锁，这样的话效率太低，而我们有意向锁
	 只需要判断是否有意向锁即可，不需要再去一行行的去扫描

184.一致性协议之-ZAB协议
	zookeeper - 直译动物园管理员, 喜欢奇数不喜欢偶数
	安装完成 -- zkCli.sh -server localhost:2181
	在配置文件中dataDir所指定的目录下创建 myid文件并写入唯一服务ID
	客户端连接服务端 -- bin/zkCli.sh -server ip:port, ip:port...

	查看根节点下的所有子节点命令 -- ls /
	get -- 可以获取Zookeeper指定节点的数据内容和属性信息
	example: get /kafka
	ls2 === ls + get

	创建节点：create -s | -e  path data acl
	-s -- 顺序节点  example: create -s /zk-test 123
	-e -- 临时节点  example: create -e /zk-temp 123
 	no-option -- 永久节点 example: create /zk-permanent 123
	acl -- 权限控制

	更新节点：set path data [version]
	data -- 要更新的数据
	version -- 表示版本
	example: set /zk-permanent 456 

	删除节点： delete path [version]
	example: delete /zk-[permanent]
	注意的是：如果节点存在子节点，则无法删除，必须先删除子节点，再删除父节点

	四种节点类型:
		1. 持久 -- persistent如果不手动删除，会一直存在
		2. 临时 -- ephemeral客户端session失效就会删除节点，没有子节点
		3. 持久有序 -- persistent_sequential
		4. 临时有序 -- ephemeral_sequential 有序自增
	ZAB -- Zookeeper Atomic Broadcast -- zookeeper原子广播协议
	其他的一些一致性协议：Raft Paxos 2PC 3PC等
	ZAB协议是为分布式协调服务Zookeeper专门设计的一种支持崩溃恢复和原子广播协议
	基于该协议，Zookeeper实现了一种主备模式的系统架构来保持集群中各个副本之间数据一致性

	所有客户端写入数据都是写入到主进程(称为Leader)中，然后，由Leader复制到备份进程(称为Follower)中
	从而保证数据一致性，从设计上看，和Raft类似。复制过程类似2PC，ZAB只需要Follower有一半以上返回Ack信息就可以执行提交
	大大减小了同步阻塞，也提高了可用性

	重点介绍消息广播和崩溃恢复。整个Zookeeper就是在这两个模式之间切换，简而言之当Leader服务可以正常使用
	就进入消息广播模式，当Leader不可用时，则进入崩溃恢复模式

	ZAB协议的消息广播过程使用的是一个原子广播协议，类似一个二阶段提交过程
	对于客户端发送的写请求，全部由Leader接收，Leader将请求封装成一个事务Proposal
	将其发送给所有Follwer，然后，根据所有Follwer的反馈，如果超过半数成功响应，则执行commit操作(先提交自己，再发送commit给所有Follwer)

	还有一些细节：
	1.Leader在收到客户端请求之后，会将这个请求封装成一个事务，并给这个事务分配一个全局递增的唯一ID
	称为事务ID(ZXID)，ZAB协议需要保证事务的顺序，因此必须将每一个事务按照ZXID进行先后排序然后处理
	2.在Leader和Follwer之间还有一个消息队列，用来解耦他们之间的耦合，解除同步阻塞
	3.zookeeper集群中为保证任何所有进程能够有序的顺序执行，只能是Leader服务器接受写请求
	即使是Follower服务器接受到客户端的请求，也会转发到Leader服务器进行处理
	4.实际上，这是一种简化版本的2PC，不能解决单点问题。等会我们会讲述ZAB如何解决单点问题
	即Leader崩溃问题

	当leader崩溃(Leader失去与过半Follower的联系)，进入我们所说的崩溃恢复模式。
	问题： 
	Leader在复制数据给所有Follwer之后崩溃，怎么办？
	Leader在收到Ack并提交了自己，同时发送了部分commit出去之后崩溃怎么办？

	针对这些问题，ZAB定义了2个原则：
	ZAB协议确保那些已经在Leader提交的事务最终会被所有服务器提交。
	ZAB协议确保丢弃那些只在Leader提出复制，但没有提交的事务

	ZXID -- 如何生成？
	在ZAB协议的事务编号ZXID设计中，ZXID是一个64位的数字，其中低32位可以看作是一个简单的递增的计数器
	针对客户端的每一个事务请求，Leader都会产生一个新的事务Proposal并对该计数器进行+1操作
	而高32位则代表了Leader服务器上取出本地日志中最大事务Proposal的ZXID，并从该ZXID中解析出对应的epoch值
	然后再对这个值加一，高32位代表了每代Leader的唯一性，低32代表了每代Leader中事务的唯一性

	ZAB让整个Zookeeper集群在两个模式之间转换，消息广播和崩溃恢复，消息广播可以说是一个简化版本的2PC
	通过崩溃恢复解决了2PC的单点问题，通过队列解决了2PC的同步阻塞问题
	而支持崩溃恢复后数据准确性的就是数据同步了，数据同步基于事务的ZXID的唯一性来保证
	通过+1操作可以辨别事务的先后顺序

	ZAB是实践算法(依赖了Paxos的思想做了简化)，Paxos属于理论的算法

185. mybatis缓存
		一级缓存： Executor中有一个local-cache，当用户发起查询时
		Mybatis会根据当前执行的MappedStatement生成一个key，去Local Cache中查询
		如果缓存命中的话，返回。如果缓存没有命中的话，则写入Local Cache，最后返回结果给用户

		Executor: 具体用来和数据库交互的执行器，接受MappedStatement作为参数
		MappedStatement: 代表要发往数据库执行的指令，可以理解为是Sql的抽象表示
		SqlSession : 代表和数据库的一次会话，向用户提供了操作数据库的方法

		Mybatis一级缓存的生命周期和SqlSession一致。
		Mybatis的缓存是一个粗粒度的缓存，没有更新缓存和缓存过期的概念，同时只是使用了默认的hashmap
		也没有做容量上的限定。因此有多个SqlSession或者分布式的环境下，有操作数据库写的话，会引起脏数据
		建议是把一级缓存的默认级别设定为Statement，即不使用一级缓存

		二级缓存: ....

		结论 -- 不建议使用mybatis缓存

186. linux -- cpu占用较高排查办法
	 一、top -- 能看到占用CPU较高的进程PID
	 command: top命令之后，(shift + h)切换进程与线程视图
	 二、通过top命令定位问题进程中每个线程占用CPU情况
	 command: top -p pid -H --这里是进程的PID
	 三、比如上一步发现进程pid-xxx中PID41892线程占用的CPU过高，就将这个线程PID转换成16进制
	 易知，PID41892转化成16进制为a3a4。使用如下命令命令定位问题代码：
	 command: jstack pid-xxx | grep a3a4 
	 jstack -- 进程堆栈跟踪工具
	 结果可能如下：
	 	"Thread" prio=10 tid=0x00007f950043e000 nid=0x54ee in test()；
	 进而定位到问题...

187. 为什么FixedThreadExecutor的corePoolSize和maximumPoolSize要设计成一样的?
	 因为线程池是先判断corePoolSize,再判断workQueue,最后判断maximumPoolSize
	 然而LinkedBlockingQueue是无界队列,所以他是达不到判断maximumPoolSize这一步的
	 所以maximumPoolSize设置成多少,没有多大关系

	 为什么CachedThreadExecutor的maximumPoolSize要设计成接近无限大的?
	 SynchronousQueue的容量很小,如果maximumPoolSize设置的很小的话，那么很容易动不动的就抛出异常

188. SPI的全名为(Service Provider Interface),是jdk内置的一种服务发现提供机制。可以理解为：
	 当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件
	 该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候
	 就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入

	 SPI机制是一种将服务接口与服务实现分离以达到解耦、大大提升程序可扩展性的机制
	 引入服务提供者就是引入了spi接口的实现者，通过本地的注册发现获取到具体的实现类，轻松可插拔

	 具体应用 -- 日志接口，jdbc驱动接口等等...
	 API -- 是给使用者用的
	 SPI -- 是给拓展者用的

189. 布隆过滤器（Bloom Filter）是对位图（BitMap）算法的一种改进
	 位图法：就是用每一位来存放某种状态，适用于大规模数据，但数据状态又不是很多的情况
	 位图法有一个优势就是空间不随集合内元素个数的增加而增加
	 它的存储空间计算方式是找到所有元素里面最大的元素（假设为 N ），因此所占空间为
	 s = N/8 Byte
	 这其实就会带来一个问题，如果查找的元素数量少但其中某个元素的值很大
	 比如数字范围是1到1000亿，那消耗的空间不容乐观，而此时使用布隆过滤器是最好的选择

	 Bloom Filter它实际上是一个很长的二进制矢量和一系列随机映射函数
	 它可以用来判断一个元素是否在一个集合中。它的优势是只需要占用很小的内存空间以及有着高效的查询效率
	 对于布隆过滤器而言，它的本质是一个位数组
	 位数组就是数组的每个元素都只占用1bit ，并且每个元素只能是0或者1
	 布隆过滤器除了一个位数组，还有K个哈希函数。当一个元素加入布隆过滤器中的时候，会进行如下操作：
		使用K个哈希函数对元素值进行K次计算，得到K个哈希值
		根据得到的哈希值，在位数组中把对应下标的值置为1
	 当判断一个元素是否在布隆过滤器中：
	    对值进行k次哈希计算，得到k个值 n1, n2, n3...得到值之后判断位数组中的每个元素是否都为1，如果值都为1
		那么说明这个值在布隆过滤器中，如果存在一个值不为1，说明该元素不在布隆过滤器中
		判断一个元素是否在布隆过滤器中时，有可能会误判，当一个不在布隆过滤器中的元素，经过同样规则的哈希计算之后
		得到的值在位数组中查询，有可能这些位置因为之前其它元素的操作先被置为1了

	 总结：布隆过滤器说某个元素在，可能会被误判。布隆过滤器说某个元素不在，那么一定不在
	 用英文说就是：False is always false. True is maybe true

190. 跳跃表(skiplist)是一种基于有序链表的扩展，简称跳表：
	 有序链表，不能进行二分查找操作，因为链表没有索引
	 那么就在链表的基础上一层一层的抽取索引，类似于二分查找的规则

	 元素添加，新节点和各层索引节点逐一比较，确定原链表的插入位置
	 利用抛硬币的随机方式，决定新节点是否提升为上一级索引。结果为“正”则提升并继续抛硬币，结果为“负”则停止
	 总体上，跳跃表插入操作的时间复杂度是O(logn)

	 元素删除，自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点
	 删除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）
	 总体上，跳跃表删除操作的时间复杂度是O(logn)

	 跳跃表的优点是维持结构平衡的成本比较低，完全依靠随机，而二分查找数在多次进程插入和删除操作之后
	 需要Reblance来重新调整结构平衡

192. 数据结构 -- 图 graph
	 理论上，图就是一堆顶点和边对象而已，但是怎么在代码中来描述呢？
	 邻接列表和邻接矩阵
	 广度优先搜索简称BFS(Breadth First Search)是一种从最初的顶点开始，优先访问所有相邻顶点的搜索方法
	 深度优先遍历简称DFS(Depth First Search)，先深入探索，走到头再回退寻找其他出路的遍历方式，就叫做深度优先遍历

193. 搜索引擎的三大过程
	 爬取内容
	 进行分词
	 建立倒排序索引

194. springboot定时器三种模式
	 @Scheduled(fixedDelay= 3*1000,initialDelay= 2*1000)
	 	上一次任务执行完成之后，间隔3秒，执行下一次的任务
		侧重点在于每次任务的间隔是3秒...
	 @Scheduled(cron="0/5 * * * * ?")  -- 不支持 initialDelay参数
	 	每间隔5秒检测一次，可以执行就执行，不可以执行放弃
		侧重点在于每隔多久执行一次任务
	 @Scheduled(fixedRate = 3*1000，initialDelay = 2*1000)
	 	上一次任务执行完之后，如果间隔超过3秒，则马上执行下一次任务
		如果间隔未超过3秒，则等到间隔到了3秒执行下次任务
		侧重点，间隔与任务兼而有之

195. LVM -- (Logical Volume Manager)逻辑卷管理，简称磁盘管理
	 LVM工作原理 ---
	 	几个概念：
		①PE　(Physical Extend)物理拓展
		②PV　(Physical Volume)物理卷
		③VG　(Volume Group)卷组
		④LV　(Logical Volume)逻辑卷
		管理过程：
		(1)物理磁盘被格式化为PV，空间被划分为一个个的PE(PE默认大小为4M)
		(2)不同的PV加入到同一个VG中，不同PV的PE全部进入到了VG的PE池内
		(3)LV基于PE创建，大小为PE的整数倍，组成LV的PE可能来自不同的物理磁盘
		(4)LV现在就直接可以格式化后挂载使用了
		(5)LV的扩充缩减实际上就是增加或减少组成该LV的PE数量，其过程不会丢失原始数据

196. LVS -- 是什么？Linux Virtual Server  -- Linux虚拟服务器
	 是一个开源的负载均衡项目，目前已经被集成到linux内核当中，一般nginx之上的负载均衡用LVS来做

197. Http服务访问Https的服务，使用spring提供的RestTemplate
	 基本都是会报错的，二个问题：
	 第一、http请求访问https的服务，是不行的，http(client端)需要安装https(服务端)的证书
	 	相关命令 -- 
		导入证书命令
		keytool -keystore cacerts -import -alias servercazhs1 -trustcacerts -file xxxx.pem

		查看是否导入成功
		keytool -list -keystore cacerts -v

		输入密钥库口令:  changeit

		安装到什么地方呢？
		jdk/jre/lib/security/cacerts  -- 注意这里的cacerts是一个文件，执行上面的命令即可，需要root权限

198. 设计模式
	 总的来说，设计模式分为三大类：
	 1> 创建型模式，有五种
	 	工厂方法模式，抽象工厂模式，单例模式，建造者模式，原型模式
	 2> 结构型模式，有七种
	 	适配器模式，装饰器模式，代理模式，外观模式，桥接模式，组合模式，享元模式
	 3> 行为型模式，有十一种
	 	观察者模式，模板方法模式，策略模式，迭代子模式，责任链模式，命令模式，解释器模式
		备忘录模式，状态模式，访问者模式，中介者模式

199. 一般出现随机的异常，根据经验，主要从两个方向入手
	 第一、根据多个异常的情况的入参数据来分析，看看多个异常情况的入参数据都有什么特点
	 第二、模拟并发量，因为很多问题本地重现不了是因为并发量不够

200. jenkins -- 一些配置

	 Name		： 这里是自定义的ssh远程服务器，如果有多台,点击add post-build step 继续添加
	 Source files	： 源文件地址，相对地址 比如 /root/.jenkins/workspace/jobname/target/xx.war  直接写成 target/xx.war就行
	 Remove prefix	： 这里指的是忽略前面的 target/   远程服务器直接显示就是xx.war
	 Remote directory    ： 远程服务器要保存的文件目录
	 Exec command	： 这里直接写 bash 脚本名称 xx.sh    这里也是远程服务器的脚本
	 Passphrase： 密码（目标机器的密码）

	 jenkins配置 SonarQube
	 sonar.projectKey=songer
	 sonar.projectName=molto-ms-pipline-account
	 sonar.projectVersion=1.0
	 sonar.sourceEncoding=UTF-8
	 sonar.language=java
	 sonar.sources=src/main/java
	 sonar.scm.disable=true
	 sonar.java.binaries=target/classes

	 npm install chromedriver --chromedriver_cdnurl=http://cdn.npm.taobao.org/dist/chromedriver
	 npm install
	 npm run build 
	 cd dist
	 echo "before--scp"
	 scp ./* wwei@172.17.222.159:/home/wwei/pixel-vue-dev/
	 echo "transfer success"
	 rm -rf *
	 echo "delete success"
	 echo "after--scp"
	 ssh wwei@172.17.222.159 
	 cd /home/wwei/pixel-vue-dev && tar -zxvf dist.tar.gz
	 echo "has reached dev-server"
	 chmod -R 755 ./*

201. 几种IO类型
	 1>分为同步IO和异步IO  -- Synchronous  Asynchronous
	 关注的是消息通知机制：消息是如何通知给调用者的

	 同步：调用发出之后不会立即返回，但一旦返回，返回即是最终结果。理解：发出请求等待结果
	 异步：调用发出之后，被调用方立即返回消息，但返回的并非最终结果，之后被调用者通过回调函数
	 状态等通知机制通知调用者来处理结果。理解：调用者发出请求，被调用者立即返回--请求已收到，请等待处理结果

	 2>分为阻塞IO和非阻塞IO -- block nonblock
	 关注的是调用者等待被调用者返回结果（这一中间过程）时的状态!!!!调用结果返回之前，调用者处于什么样的状态

	 阻塞：调用结果返回之前，调用者被挂起（不可中断睡眠状态），调用者只有在得到返回结果之后才能继续
	 非阻塞：调用结果返回之前，调用者不会被挂起。理解一次请求，结果没返回之前，不会阻塞当前线程

	 目前常用的IO模型有五种：
	 a:blocking IO:阻塞式IO
	 
	 b:nonblicking IO：非阻塞式IO
	 
	 c:IO multiplexing:复用型IO

	 select（）多路IO调用模型，最多承载1024个并发...
	 内核中复用型IO的代理。
	 所以复用型IO是阻塞式IO，但阻塞发生在代理之上。
	 对性能并没有提升，最多只是额外可以处理另外的事情而已...

	 d:signal driven IO:事件驱动IO
	 调用者发出请求，被调用者收到请求立刻通知，请求已收到，该干什么干什么去，但当磁盘到内核IO完毕会通知调用者
	 接下来调用者等待内核到该进程IO,这一阶段是阻塞状态、通知机制：水平触发，多次通知、边缘触发，只通知一次

	 e:asynchronous IO：异步IO

	 从磁盘做一次read操作、就是一个读请求、可以简单的看做2个步骤
	 第一步 -- 内核（系统程序）要把数据从磁盘加载至内核自己的内存
	 第二步 -- 在内核中把数据copy一份，复制到进程内存（应用程序的内存）
	 真正成为IO的是第二步：数据从内核内存到进程内存（应用内存）

	接下来会颠覆认知的一些理解，或许这就是真实的....
	@@-从Linux操作系统层面理解到底什么是Block
	很多人说BIO不好，会“block”，但到底什么是IO的Block呢？考虑下面两种情况
	1、用系统调用read从socket里读取一段数据
	2、用系统调用read从一个磁盘文件读取一段数据到内存
	如果你的直觉告诉你，这两种都算“Block”，那么很遗憾，你的理解与Linux不同。Linux认为
	对于第一种情况，算作block，因为Linux无法知道网络上对方是否会发数据。如果没数据发过来
	对于调用read的程序来说，就只能“等”
	对于第二种情况，不算做block。是的，对于磁盘文件IO，Linux总是不视作Block

	你可能会说，这不科学啊，磁盘读写偶尔也会因为硬件而卡壳啊，怎么能不算Block呢？但实际就是不算
	一个解释是，所谓“Block”是指操作系统可以预见这个Block会发生才会主动Block。例如当读取TCP连接的数据时
	如果发现Socket buffer里没有数据就可以确定对方还没有发过来，于是Block，而对于普通磁盘文件的读写
	也许磁盘运作期间会抖动，会短暂暂停，但是操作系统无法预见这种情况，只能视作不会Block，照样执行

	基于这个基本的设定，在讨论IO时，一定要严格区分网络IO和磁盘文件IO
	NIO和后文讲到的IO多路复用只对网络IO有意义
	IO多路复用仅仅是操作系统提供的一种便利的通知机制，IO多路复用和NIO是要配合一起使用才有实际意义

	一下是一些对IO多路复用的一些误解
	1、IO多路复用是指多个数据流共享同一个Socket。其实IO多路复用说的是多个Socket，只不过操作系统是一起监听他们的事件而已
	多个数据流共享同一个TCP连接的场景的确是有，比如Http2 Multiplexing就是指Http2通讯中中多个逻辑的数据流共享同一个TCP连接
	但这与IO多路复用是完全不同的问题
	2、IO多路复用是NIO，所以总是不Block的。其实IO多路复用的关键API调用(select，poll，epoll_wait)总是Block的
	3、IO多路复用和NIO一起减少了IO。实际上，IO本身（网络数据的收发）无论用不用IO多路复用和NIO，都没有变化
	请求的数据该是多少还是多少。网络上该传输多少数据还是多少数据。IO多路复用和NIO一起仅仅是解决了调度的问题
	避免CPU在这个过程中的浪费，使系统的瓶颈更容易触达到网络带宽，而非CPU或者内存
	要提高IO吞吐，还是提高硬件的容量（例如，用支持更大带宽的网线、网卡和交换机）和依靠并发传输（例如HDFS的数据多副本并发传输）

	操作系统级别提供了一些接口来支持IO多路复用，最老掉牙的是select和poll，目前来看，高性能的web服务器都不会使用select和poll
	他们俩存在的意义仅仅是“兼容性”。在Linux上提供了epoll api。它们的出现彻底解决了select和poll的问题
	Java NIO，nginx等在对应的平台的上都是使用这些api实现的

	简单说就是select和poll的代价是"O(所有注册事件fd的数量)"，而epoll的代价是"O(发生事件fd的数量)"
	于是，高性能网络服务器的场景特别适合用epoll来实现——因为大多数网络服务器都有这样的模式
	同时要监听大量（几千，几万，几十万甚至更多）的网络连接，但是短时间内发生的事件非常少


202. 数据库优化：
	 1>:建立适当的冗余字段
	 2>:建立索引
	 3>:建表原则  
	 -- 定长与变长字段分离，变长字段和不经常查询的字段放在
		一张表里面。常用字段和不常用字段相分离。能用tinyint就要用int
		字符串（要考虑字符集与校对集--排序规则）
		能用整形就不要用字符串
		能定长的字段就不要用变长的字段
		列的选择尽量少用null,null会占据更大的空间。
	 查询，只能用一个独立的索引，所以建立多个索引的意思不大。
	 正常是建立联合索引，就是把多个列看成一个整体，给这个整体建立一个索引
	 建立联合索引 index(a,b,c) --和顺序有严格的关系，注意顺序。
	 b+tree索引 --- 左前缀原则...
	 一个网站的优化，离不开实际的调研...
	 查看sql执行细节：
	 explain select * from dual \G

	 大部分情况下连接查询效率高于子查询
	 可以用 explain 和 profile分析查询语句
	 1、慢查询 （分析出现出问题的sql）
	 2、Explain （显示了mysql如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句）
	 3、Profile（查询到SQL会执行多少时间, 并看出CPU/Memory使用量, 执行过程中Systemlock，Table lock 花多少时间等等
	 大的sql可以分成几个小的sql，表中可以建立适当的冗余字段


203. jsp动态包含与静态包含的区别？
	 动态包含：<jsp:include page='file.jsp'/>
	 发生在执行class文件阶段，动态加入。生成多个class文件，是编译之后执行结果的拼接
	 静态包含：<% @include file=''>
	 发生在jsp --- >java文件阶段。生成一个class文件。是编译阶段的代码拼接

204. jvm -- 由四部分组成？
	 1.类加载器 -- 加载类
	 2.执行引擎，执行java字节码指令
	 3.内存区域，（运行时数据区域）
	 内存区由五部分组成：
		 方法区：存储类结构信息，静态变量，常量池，构造方法等，non-heap(非堆)

		 java堆:(heap),java实例对象，java堆和方法区是被java所有线程共享的区域

		 java栈：总是与线程关联在一起的，每当创建一个线程的时候，jvm就会给这个线程创建一个栈(stack)
		 在这个栈中又会包含多个栈帧，每运行一个放法就会创建一个栈帧，用于保存局部变量，方法返回值等
		 每一个方法从开始调用到执行完毕的过程，就对应一个栈帧在java栈中从入栈到出栈的过程，是线程私有的

		 程序计数器：(PC Register)用于保存当前线程的执行状态，jvm程序是多线程的,（线程轮流切换执行），保证线程
		 切换回来之后还能回到到之前的状态，就需要一个独立的计数器，记录之前中断的地方，程序计数器也是线程私有的
		
		 本地方法栈：(native method stack),和java栈的功能类似，只不过是为jvm使用到的native方法服务的			
				
	 4.本地库接口，调用其他语言实现的本地方法

205. FreeMarker -- 模板引擎
	 <#if erp.age lt || gt 12>
		 ${emp.age}
	 </#if>

	 <#list emps as emp>
		 ${emp.age}
	 </#list>

	 调用函数的时候后面跟？
	 ${username?replace(param1.param2....)}

	 <#include /inc/..ftl/> --引入另一个模板文件
	 <#import /inc/..ftl/ as alias> 可以定义一个别名作为命名空间
	 这样可以避免变量冲突问题。
	 处理空值 ---要手动处理，否则报错，这里不同于el表达式，
	 ${emp.group!} --如果是空，什么都不显示。
	 ${emp.group!("没有group")} --
	 对象导航 -- 建议使用（）
	 ${(emp.group.name)!}

	 判断对象时候为空？
	 <#if (a.b)??>
		 判断a.b是否为空
	 </#if>

	 输出a.b是空、怎么输出？
	 ${(a.b)???string} -- false

	 <#assign n = "1"/> -- 定义一个变量
	 对于freemarker而言，用${}这种方式只能输出数字和字符串，
	 对于其他的类型都不行
	 另外如果处理map，key只能是string类型。 

	 <#assing flag = true/>
	 ${flag}  --- error
	 ${flag?string} --- yes
	 ${flag?string("yes","no")} -- yes
	 ${.now} --- 当前的系统日期和时间，格式化过的。

	 变量作用域 ---
		 数据模型变量 -- root中的变量
		 模板变量 -- 通过 assign 在模板中定义的变量
		 局部变量
		 循环遍历 -- 

		 原则 -- 优先模板变量，找不到再去找模型变量。
		 如果直接拿模型数据 --- ${.globals.field}

	 创建一个数组：<#assign num=1..100/>
	 可以使用<#list/>循环出值。
	 ${"这个世家！！！！1”[0..3]}... 

206.spring中Bean的作用域
	singleton --默认
	prototype --每次从容器中获取Bean是都会创建一个
	request -- 一次请求创建一个
	session -- 一个会话级别
	global session -- 全局的

	为什么默认是singleton？
	1>为了性能
	2>不需要多例
	多例也可以，就是在class上面加@Sope('request or prototype')
	但是最佳实践，不要在controller里定义成员变量

	几种增强类型：
	before -- 目标方法前织入增强处理
	afterReturning -- 目标方法正常执行，不出现异常，后织入增强处理
	afterThrowing -- 目标方法抛出异常后，织入增强处理
	after -- 不论是否抛出异常，目标方法执行之后织入增强处理
	around -- 目标方法的前后都织入增强处理

207. 分布式应用场景的常见问题：
		统一服务器名称
		统一配置管理
		分布式通知/协调
		共享锁
		队列管理
		master选举
     队里queue的应用场景：
		串行任务得时候，节约程序的执行时间
		模块或是应用之间解耦
		流量削峰 -- 秒杀的时候，高并发的时候，把请求放入消息队列。最终不至于服务挂掉
		日志处理 -- 
		消息通讯 --纯粹的消息通讯，点对点，发布订阅等

209. hashmap的实现原理：
	 一个元素是Entry<E>的数组 --- 
	 数组的每个下标就是一个桶，哈希表是由数组+链表组成的，一个长度为16的数组中，每个元素存储的是一个链表的头结点
	 那么这些元素是按照什么样的规则存储到数组中呢。一般情况是通过hash(key)%len获得
	 也就是元素的key的哈希值对数组长度取模得到。打个比方， 第一个键值对A进来，通过计算其key的hash得到的index=0
	 记做:Entry[0] = A。一会后又进来一个键值对B，通过计算其index也等于0，现在怎么办？
	 HashMap会这样做:B.next = A,Entry[0] = B,如果又进来C,index也等于0,那么C.next = B,Entry[0] = C
	 这样我们发现index=0的地方其实存取了A,B,C三个键值对,他们通过next这个属性链接在一起。这里的next就是一个指针。
	 Entry<k,v> implements Map.Entry<k,v>{
					final k key;
					v value;
					Entry<k,v> next;
					int hash; //存放当前key的hashCode
				}

	 解决hash冲突的方法：
		 1.开放定址法 2.链地址法 ---java中采用的 3.再哈希法 4.建立一个公共的溢出区

	 HashSet--接口原理相关
	 如果将对象存入hashSet中 ：第一件事是重写 equals()和hashCode()方法、以确保对象的值是否相等
	 hashSet的底层实现就是hashMap，为什么要重写equals和hashcode方法？保证元素的唯一性
	 总体的思路：hashCode不同，必定不是同一个对象，如果hashcode相同则再根据equals方法判断是否为同一个对象
	 按照Object类的hashCode方法，是不可能返回两个相同的哈希码的

	 解释 -- 即使两个对象的属性相同，返回的也不是同一个hash码，与现实不符，属性都相同，怎么可能不是同一个对象呢？
	 所以要重写hashcode方法，（现实逻辑，属性相同的对象被看做是同一个对象）这是也我们重写hashcode的宗旨和目的！
	 
	 面临的问题 -- 重写hashCode的时候，即使我们重写了，总会有一个bug那就是，两个属性不同的对象
	 有可能返回同样的hash码，为了解决这个问题，在哈希码相同的情况下
	 我们只能重写equals方法，来比较两个对象的属性是否相同，来做到万无一失

	 这里说下 == 与 equals()方法比较的区别
	 == 比较的是变量的值是否相等
	 Object类中equals()方法内部使用 == 运算符，在没有覆盖equals()方法的情况下，如果是对象使用equals()方法进行比较
	 比较的是两个对象的内存地址值。但是一些特殊的类复写了equal()方法，比如String、Integer、Date等，所以这些类的对象
	 使用equals()方法进行比较的话，比较的就不是对象的内存地址


210. 线程池相关的东西 - java.util.concurrent
	 newCachedThreadPool ---创建一个可缓存线程池，如果线程池长度超过处理需要
	 可灵活回收空闲线程，若无可回收，则新建线程
	 newFixedThreadPool ---创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程
	 如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中
	 newSingleThreadExecutor ---创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务
	 它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行
	 如果这个线程异常结束，会有另一个取代它，保证顺序执行
	 单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的
	 newScheduleThreadPool ---创建一个定长的线程池，而且支持定时的以及周期性的任务执行
	 支持定时及周期性任务执行

211. 同步容器 -- （hashTable,vector）
     并发容器 --- （concurrentHashMap,CopyOnWriteArrayList,CopyOnWriteArraySet）、
	 提高了并发性能，同时还保证了线程安全性，使用ReentrantLock锁，体现了一种读写分离的思想
	 只能保持数据的最终一致性，不能保持实时的一致性
	 copyonwrite --顾名思义，就是在write之前，对集合进行copy,针对容器的任意修改操作都是在容器的副本上进行的
	 并且在修改之后，将原容器的引用指向副本。在迭代期间不会对容器进行加锁或是复制
	 缺点、内存占用问题，内存占用较大，就会引发频繁的垃圾回收
	 数据一致性问题，读操作没有用到并发控制，读取的数据可能不一致
	 应用场景：迭代操作多余修改操作的时候。读操作多余写操作 - 读多写少
	
	 阻塞队列（BlockingQueue）JUC包下重要的数据结构
	 BlockingQueue提供了线程安全的队列访问方式：当阻塞队列进行插入数据时，如果队列已满
	 线程将会阻塞等待直到队列非满；从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空
	 并发包下很多高级同步类的实现都是基于BlockingQueue实现的

     队列：是一种特殊的线性表
	 只允许在表的前端进行删除操作(front-队首)，在表的后端进行插入操作(rear-队尾)

	 java1.5以后current包中的阻塞队列：
	 ArrayBlockingQueue:初始化必须指定大小 ---使用重入锁，有界队列
	 LinkedBlockingQueue:默认为Integer的最大值 ---两个锁，放锁和拿锁，无界队列
	 PriorityBlockingQueue:无界队列
	 DelayQueue:基于PriorityBlockingQueue实现。
	 相关的三个添加和删除方法：
	 add() -- 返回true ,满了会抛异常 --IllegalStateException
	 offer()--返回 true,false
	 put()--如果满了会阻塞队列

	 poll() --返回null或元素
	 remove() --返回true,false
	 take() --队列为空会阻塞

212. HashMap与ConcurrentHashMap的区别？锁的粒度以及如何锁的问题
	 JDK1.5有了concurrent包：
	 首先：ConcurrentHashMap肯定是线程安全的。
	 ConcurrentHashMap：引入一个分段锁的概念(锁分离技术)，具体就是把一个map拆分成n个小的HashTable
	 根据key.hashCode()来决定把value放到哪个HashTable中去，put和get的时候都是根据key.hashCode()
	 算出放到哪一个segment中。segment是默认初始化为长度为16的数组。所以理论上算性能就提高了16倍
	 synchronized是针对整整hash表，一把锁。而concurrenthashmap允许多个修改操作并发执行
	 关键在于使用了多个锁对hash表的不同segment进行控制，每个segment都有自己不同的锁
	 只要多个修改发生在不同的segment(段)上，那么他们就能并发执行，每个段（segment）相当于一个小的hashtable
	 某些方法需要跨段执行，如size(),containsValue()等，它们需要锁定整个表
	 而不是某一段，这需要按顺序锁定所有的段，执行完成之后，在按顺序解锁所有的段，这里的按顺序很重要
	 否则会出现死锁，在concurrenthashmap内部segment数组是final的
	 增容问题？loadFactor = 0.75 默认数组长度为16 16*0.75 = 12

	 hash表中桶的数量  -- 就是我们经常理解的容量

	 这里所说的ConcurrentHashMap的原理是jdk1.7的实现，而jdk1.8的实现与之前的差异很大，1.8的实现已经抛弃了Segment分段锁机制
	 利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构

	 string的hashCode()方法：
		 public int hashCode(){
			 int h = hash;
			 //这里的value就是字符串...比如 ‘older’
			 if(h == 0 && value.length > 0){
				 Char [] arr = value;
				 for(int i = 0; i < value.length;i++){\
					 h = h * 31 +arr[i];
				 }
				 hash = h;
			 }
			 return h;
		 }

213. 什么是缓存穿透？什么是缓存雪崩？应该如何避免？
	 缓存穿透：一般的缓存基本上都是按着key去缓存查询，如果不存在对应的value,就会直接去后端系统查询(比如DB)
	 如果key对应的value是一定不存在的，并且并发请求量很大，就会对后端系统造成很大的压力，这就是缓存穿透
	 应对：对查询结果为空的情况也进行缓存...时间可以设置短一些，对一定不存在value的key进行过滤。

	 缓存雪崩：当缓存服务器重启或是大量缓存集中在某一时间段失效的情况下，也会给后端系统带来很大的压力，这就是缓存雪崩。
	 1.缓存失效后，可以对缓存的读写加锁
	 2.不同的key设置均匀的过期时间，避免集中某一个时间段，缓存集体失效
	 3.做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效可以访问A2,A1的时间可以设短点，A2的时间设长点

     分布式缓存系统面临的问题
	 缓存一致性问题
	 1：缓存系统与底层数据的一致性。这点在底层系统是“可读可写”时，写得尤为重要 
	 2：有继承关系的缓存之间的一致性。为了尽量提高缓存命中率，缓存也是分层：全局缓存，二级缓存
	 他们是存在继承关系的。全局缓存可以有二级缓存来组成 
	 3：多个缓存副本之间的一致性。为了保证系统的高可用性，缓存系统背后往往会接两套存储系统（如memcache，redis等）

	 缓存数据的淘汰
	 缓存淘汰的策略有两种：
	 (1) 定时去清理过期的缓存
	 (2)当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存 
	 两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效
	 逻辑相对比较复杂，具体用哪种方案，大家可以根据自己的应用场景来权衡
	 1. 预估失效时间 2. 版本号（必须单调递增，时间戳是最好的选择）3. 提供手动清理缓存的接口

214. HashMap的两种遍历方式：
     Map map = new HashMap();

     Iterator iter = map.keySet().iterator();
		while (iter.hasNext()) {
	　　Object key = iter.next();
	　　Object val = map.get(key);
　　 }
　　 效率低,以后尽量少使用！

     Iterator iter = map.entrySet().iterator();
　　 while (iter.hasNext()) {
	　　 Map.Entry entry = (Map.Entry) iter.next();
	　　 Object key = entry.getKey();
	　　 Object val = entry.getValue();
　　 }
　　 效率高,以后一定要使用此种方式！

	对于集合的遍历操作，如果中间步骤有删除操作的话
	foreach循环和迭代器循环会抛出异常
	应该用普通的for循环



217. trie树 -- [traɪ]、又称单词查找树、字典树，是一种树形结构，用于保存大量的字符串
	 它的优点是：利用字符串的公共前缀来节约存储空间
	 trie树的根节点不存任何数据，每整个分支代表一个完整的字符串

218. 获取Class对象的三种方法：
	 1.根据对象的引用.getClass()方法获取
		MyObject object=new MyObject();
		Class c=object.getClass();
	 2.根据类名.class获取
	 	Class c=MyObject.class;
	 3.根据Class中的静态方法Class.forName()
	   Class	c=Class.forName("MyObject");

219. mysql一些知识拾遗
	 导出整个数据库
		mysqldump -u dbuser -p dbname > dbname.sql
	 导出一个表
		mysqldump -u dbuser -p dbname tablename > dbname_users.sql
	 导出一个数据库结构
		mysqldump -u dbuser -p -d --add-drop-table dbname >d:/dbname_db.sql
		-d 没有数据 --add-drop-table 在每个create语句之前增加一个drop table

	 导入数据库
		mysql -u root -p
		mysql>use 数据库
		然后使用source命令，后面参数为脚本文件(如这里用到的.sql)
		mysql>source d:/dbname.sql
		mysql -u用户名 -p密码 数据库名 < 数据库名.sql

	 myssql中explain和profile的使用方法：
		使用 --  explain sql ....
		explain --- 显示了sql的表连接和索引的使用情况,有几列字段
		id -- SELECT识别符。这是SELECT的查询序列号
		select_type -- SELECT类型,可以为以下任何一种
			SIMPLE:简单SELECT(不使用UNION或子查询)
			PRIMARY:最外面的SELECT
			UNION:UNION中的第二个或后面的SELECT语句
			DEPENDENT UNION:UNION中的第二个或后面的SELECT语句,取决于外面的查询
			UNION RESULT:UNION 的结果
			SUBQUERY:子查询中的第一个SELECT
			DEPENDENT SUBQUERY:子查询中的第一个SELECT,取决于外面的查询
			DERIVED:导出表的SELECT(FROM子句的子查询)
		table:输出的行所引用的表
		type:联接类型。下面给出各种联接类型,按照从最佳类型到最坏类型进行排序:
			system:表仅有一行(=系统表)。这是const联接类型的一个特例。
			const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次!
			eq_ref:对于每个来自于前面的表的行组合,从该表中读取一行。这可能是最好的联接类型,除了const类型。
			ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取。
			ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。
			index_merge:该联接类型表示使用了索引合并优化方法。
			unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。
			index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr)
			range:只检索给定范围的行,使用一个索引来选择行。
			index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。
			ALL:对于每个来自于先前的表的行组合,进行完整的表扫描。
		possible_keys:指出MySQL能使用哪个索引在该表中找到行
		key:显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL。
		key_len:显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL。
		ref:显示使用哪个列或常数与key一起从表中选择行。
		rows:显示MySQL认为它执行查询时必须检查的行数。多行之间的数据相乘可以估算要处理的行数。
		filtered:显示了通过条件过滤出的行数的百分比估计值。
		Extra:该列包含MySQL解决查询的详细信息
			Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。
			Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。
			range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。
			Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。
			Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。
			Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。
			Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。
			Using sort_union(...), Using union(...), Using intersect(...):这些函数说明如何为index_merge联接类型合并索引扫描。
			Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。

 	 profile -- 了解SQL语句消耗资源的详细信息
 		1. 查看是否已经启用profile，默认是关闭的
 		   select @@profiling;
 		   0 -- 未启用
 		   1 -- 已启用
		2. 启用profiling。变量profiling是用户变量，每次都得重新启用
		   set profiling = 1;
		3. 执行一条sql语句  example: select * from dual .....
		4. show profile;  --- 查询最近一条语句的执行信息
		   show profile;
		5. 使用show profiles。查看在服务器上执行语句的列表
		   show profiles;
		6. 使用 show profile for query qurery_id --- 分析列表中的查询语句信息
		   show profile for query 6;
		7. 获取 CPU 和 Block IO 的消耗
			show profile block io,cpu for query 6;
			show profile all for query 6;
			show profile cpu,block io,memory,swaps,context switches,source for query 6;
			......

	 MySQL默认采用的引擎是MyISAM
	 MyISAM不支持事务，而InnoDB支持。InnoDB的AUTOCOMMIT默认是打开的，即每条SQL语句会默认被封装成一个事务
	 自动提交，这样会影响速度，所以最好是把多条SQL语句显示放在begin和commit之间，组成一个事务去提交
	 InnoDB支持数据行锁定，MyISAM不支持行锁定，只支持锁定整个表。即MyISAM同一个表上的读锁和写锁是互斥的
	 MyISAM并发读写时如果等待队列中既有读请求又有写请求，默认写请求的优先级高，即便是读请求先到...
	 所以MyISAM不适合于有大量查询和修改并存的情况，那样查询进程会长时间阻塞。因为MyISAM是锁表
	 所以某项读操作比较耗时会使其他写进程饿死。InnoDB支持外键，MyISAM不支持。InnoDB的主键范围更大
	 最大是MyISAM的2倍。InnoDB不支持全文索引，而MyISAM支持
	 全文索引是指对char、varchar和text中的每个词（停用词除外）建立倒排序索引
	 MyISAM的全文索引其实没啥用，因为它不支持中文分词，必须由使用者分词后加入空格再写到数据表里
	 而且少于4个汉字的词会和停用词一样被忽略掉
	 MyISAM支持GIS数据，InnoDB不支持。即MyISAM支持以下空间数据对象：Point,Line,Polygon,Surface等
	 没有where的count(*)使用MyISAM要比InnoDB快得多。因为MyISAM内置了一个计数器，count(*)时它直接从计数器中读
	 而InnoDB必须扫描全表，所以在InnoDB上执行count(*)时一般要伴随where，且where中要包含主键以外的索引列
	 为什么这里特别强调“主键以外”？
	 因为InnoDB中primary index是和raw data存放在一起的，而secondary index则是单独存放
	 然后有个指针指向primary key。所以只是count(*)的话使用secondary index扫描更快
	 而primary key则主要在扫描索引同时要返回raw data时的作用较大

	 propagation: spring事务的传播机制
		事务发生嵌套调用时 -- 事务是如何传播的。
		1.required -- 如果当前没有事务，就新建一个事务。如果已经存在一个事务中，则加入到这个事务中。
		2.requires_new -- 新建事务，如果当前存在事务，则把当前事务挂起。
		3.supports -- 支持当前事务，如果当前没有事务，就以非事物方式运行。
		4.mandatory（强制的） -- 使用当前事务，如果当前没有事务，则抛出异常。
		5.never -- 以非事务方式执行，如果当前存在事务，则抛出异常。
		6.not_supports -- 以非事务方式执行操作，如果当前存在事务，则挂起。

	 嵌套事务不能够提交，它必须通过外层事务来完成提交的动作，外层事务的回滚也会造成内部事务的回滚
	 PROPAGATION_REQUIRES_NEW 启动一个新的、和外层事务无关的“内部”事务。
	 该事务拥有自己的独立隔离级别和锁，不依赖于外部事务，独立地提交和回滚。当内部事务开始执行时
	 外部事务 将被挂起，内务事务结束时，外部事务才继续执行。
	 PROPAGATION_NESTED 将创建一个依赖于外层事务的子事务，当外层事务提交或回滚时，子事务也会连带提交和回滚

	 mysql不支持嵌套事物，但是可以通过savepoint和rollback to来达到一些嵌套事物的特性


	 mysql -- 主从复制步骤
		1. 主服务器
			第一 创建相应权限的账号
			第二 开启二进制日志
			第三 设置 serverID
		2. 从服务器 （必要时导入数据）
			第一 启用中继日志，可选关闭二进制日志
			第二 设置serverID
			第三 启动复制线程
		有必要基于ssl的复制，加密


	 什么是事务
		事务是一条或多条数据库操作语句的组合，具备ACID，4个特点。
		原子性：要不全部成功，要不全部撤销
		隔离性：事务之间相互独立，互不干扰
		一致性：数据库正确地改变状态后，数据库的一致��约束没有被破坏
		持久性：事务的提交结果，将持久保存在数据库中


	 事务隔离级别相关，spring有五种配置方式：
		读未提交：出现上述情况，即我们所说的脏读事务B读取了事务A尚未提交的数据。
		读已提交：出现上述情况，即我们所说的不可重复读，两个并发的事务，“事务A：singo消费”、
		“事务B：singo的老婆网上转账”，事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务
		而事务A再次读取该数据时，数据已经发生了改变。
		可重复读：


	 事务隔离级别  --- 不可重复读---产生幻读 --场景
		幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作
		这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库
		而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的
		就好像产生幻觉一样，这就是发生了幻读。

		一句话解释数据库事务的隔离级别：
		以性能为理由，对强一致性的破坏
		持久化的语义更多的体现在数据库发生故障时，确保提交的事务不丢失
		其中可重复读可以做����读读并行，读已提交写锁可以将读锁升级
		如果当前事务正在写，那么其他所有的读都将被阻塞
		所以优化的点也在这里，有没有办法让写不阻塞读呢？这样的话，可以大大提升数据库读的性能
		尤其是在读多写少的场景下，这样的性能优化尤其重要：
		MVCC模型(多版本并发控制,Multi-Version-Concurrent-Control)，每行数据有多个版本
		此模式下读分为两类：快照读(snapshot read)和当前读(current read)
		snapshot read -- 读取的是记录的可见版本(有可能是历史版本)，不需要加锁
		current read -- 读取的是记录的最新版本，加锁，保证其他事物不会并发改变这条记录
		
	 死锁的形成条件：
	 四个必要条件:
		1.独占资源，即是某一个资源在某一时间内只能被一个进程占有
		2.进程已经占有一个资源，但又申请新的资源，对已经占有的资源保持不放。
		3.举个简单的例子，系统中只有一台CD-ROM驱动器和一台打印机，某一个进程占有了CD-ROM驱动器
		又申请打印机；另一进程占有了打印机，还申请CD-ROM。结果，两个进程都被阻塞，永远也不能自行解除。这就是死锁 

		一句话概括就是、互斥，请求和保持，不剥夺，环路等待条件 

	 数据库索引：mysql btree索引，hash索引，全文索引。
		bree索引：btree有许多变种，其中B+Tree最为常见，mysql就是使用的
		B+Tree的原理：B-tree就是指的B树。特此说明B树是为了磁盘或其它存储设备而设计的一种多叉平衡查找树

	 索引的分类？
		0>主键索引，默认主键列就是索引，一种特殊的唯一索引，不允许有空值。
		1>普通索引，没什么限制...
		2>唯一索引，与普通索引类似，但索引列的值必须是唯一的，可以为空。
		3>全文索引（fulltext）mysql 3.2开始支持全文索引和全文检索，
		4>组合索引，多列组成的索引

	 聚簇索引和非聚簇索引？
		一般情况下主键会默认创建聚簇索引，且一张表只允许存在一个聚簇索引。
		聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针

220.IO与NIO的区别？
	IO		  		NIO
	面向Stream		面向Buffer
	阻塞IO			非阻塞IO
				Selectors
	IO是面向流的，NIO是面向缓冲区的。每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方
	阻塞与非阻塞IO，当一个线程调用read()或write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入
	该线程在此期间不能再干任何事情了，Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据
	但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞
	所以直至数据变的可以读取之前，该线程可以继续做其他的事情。非阻塞写也是如此。一个线程请求写入一些数据到某通道
	但不需要等待它完全写入，这个线程同时可以去做别的事情。线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作
	所以一个单独的线程现在可以管理多个输入和输出通道（channel）

	channel与流的根本区别，channel是双向的，而流是在一个方向上移动，一个流必须是(OutputStream、InputStream)的子类
	通道可以用于读、写或者两者同时进行。底层操作系统的通道基本都是全双工的，同时支持读写操作
	Java中的Channel可以分为两类、用于网络读写的SelectableChannel和用于文件操作的FileChannel

	Jdk1.4 - jdk1.6 NIO都是基于IO多路复用模型，只不过是复用器的优化而已(select/poll、epoll)
	所以只能说是非阻塞IO，而jdk1.7的NIO 2.0新增了异步套接字通道，它才是真正的异步IO，异步IO也被称为AIO

	Ractor模式，是一种应用在服务器端的开发模式，也有称之为一种IO模式，目的是提高服务端程序的并发能力
	表现就是减少等待，节省服务器资源消耗，提高服务器的并发能力

222.NodeJS ---单线程，异步，事件驱动
	js是脚本语言，需要解析器才能运行（环境）
	js脚本 --> (浏览器:解析器) -->操作DOM,允许定义各种数据结构 --浏览器提供了document等内置对象
	js脚本 --> (Nodejs:解析器) -->操作磁盘文件或是搭建HTTP服务器,允许定义各种数据结构 -- Nodejs提供了 fs,http等内置对象
	一个模块就是一个 js文件(server.js) 文件路径就是模块名称
	编写每个模块是都有三个预先定义好的变量供使用：require,exports,module
	1.require函数：当前模块中加载和使用别的模块
		var foo = require('./server.js') --> ./ 相对路径
		var too = require('/usr/home/server.js') --> / 或 c: 开始 绝对路径
		另：.js 扩展名可以省略..
		导入json文件：var json = require('./data.json') -->扩展名不可省略.
	2.exports对象：当前模块的导出对象.导出模块公有的方法和属性.
		exports.hello=function(){
			console.log('Hello');
		}
	3.module对象：可以访问模块的一些相关信息，但用途最多还是替换当前模块的导出对象.
	模块默认导出对象是一个普通对象，如果想改成一个函数：
		module.exports = function(){
			console.log('Hello');
		}
	其他模块利用require()方法时得到当前模块的对象就是 exports对象.
	tar包   $./configure (makefile) --> 检测系统配置 生成 makefile文件
		$ make -->编译
		$ sudo make install -->安装
	卸载 npm安装的全局模块  命令： npm uninstall -g <packageName>  -->亲测有效
	添加淘宝npm安装镜像 命令： npm config set registry https://registry.npm.taobao.org

	<script></script>:放置位置   1.<head></head>里    2. <body></body>  3.尾部
		如果 js要操作  Html元素   最好不要放在  <head></head>里
		页面加载顺序，由上至下，报找不到元素

	nodejs -- 安装记录
	1.官网下载安装包，修改默认安装路径
	2.安装目录下新建两个文件夹(node_global,node_cache)
	这两个文件夹名字随意，没有限制....
	3.cmd 两条命令修改全局包和缓存包路径
	npm set config prefix '....\node_global'
	npm set config cache '....\node_cache'
	----------------
	此步骤另一种方式：
	node安装目录下 \npm\找到npmrc文件
	编辑该文件添加如下：
	prefix = ...\node_global
	cache = ...\node_cache
	4.配置环境变量
	系统变量：Path 后追加node安装路径
	用户变量：Path 默认的设置改成 prefix 所设置的路径
	5.npm install相关参数问题涉及本地安装和全局安装
	npm install -g 全局安装
	npm install 或是 npm install --save 本地安装
	首先两者的包安装路径不同，安装方式也不同，本地安装会在项目的package.json文件中写入安装信息
	全局安装可以通过命令行来操作，而本地安装是通过 require关键字在项目中引用
	全局安装不能代替本地安装
	本地安装的必要性：最最关键的就是解决了不同项目对不同包的版本依赖问题
	6.npm config 或是 npm config --help可以查看config命令和config设置
	7.npm下载包使用淘宝镜像设置
	临时使用：安装某个包时使用如下命令
		$ npm --registry https://registry.npm.taobao.org install [packagename]
		将[packagename]改为想要安装的包的名字即可。
	永久使用
		$ npm config set registry https://registry.npm.taobao.org


223.Redis是一种NOSQL数据库，数据是保存内存中,可以定时把内存数据同步到磁盘（数据持久化）
	比memcached支持更多的数据结构,支持订阅和发布的功能.
	windows下：解压：命令行到解压目录 redies-server.exe redis.conf --启动
	查看：netstat aub | more  6379默认
	dbsize -- 统计总数
	flushall -- 清空
	info --查看信息
	type key -->key的数据类型
	object encoding key --> 返回底层 真实的数据结构 (hash ,sds ,linkedList  ziplist,intset,skiplist)
	redis  -- > redisObject 每种数据结构都是一个对象
	ttl --> 查看key的剩余过期时间 （-2，代表已过期，key已经不存在。-1,key存在，并且永不过期）
	遍历所有的键（key）
	命令：一：keys * ,keys [pattern]

	主从复制两种方式  
	1.slaveof   命令  
	2.conf   配置文件

	slaveof  ip  port     --->return  ok
	info replication    -->查看主从关系信息命令
	config rewrite     --->

	redis默认 开启 RDB --持久化，AOF -- 是不开启的
	RDB --创建文件的条件：
	1.手动执行 save命令
	2.手动执行 bgsave命令
	3.通过配置save选项，条件满足时，自动执行bgsave命令
	example: save 100 10 -->100s 写了10条记录..
	距上一次创建rdb文件已经过去了100s,并且服务器的所有数据库总共已经发生了不少于10次的修改
	配置里默认会写三条：多个保存的条件效果是不会累加的		
	save 900 1 @@ save 300 10 @@ save 60 10000
	RDB-- 每次都会创建一个新的 dump.rdb 文件覆盖之前生成的文件。

	bgsave --- fork一个子进程，速度较慢，适合线上情况，如果是维护的话save更合适一些，RDB不能执行过于频繁
	否则影响服务器的性能。意外停机会丢失数据。为了解决此问题，AOF持久化把丢失的数据缩减到最小

	AOF把命令写入硬盘的三个策略，配置文件
	always -- 每执行一个命令，就将系统缓冲区中的数据写入硬盘，意外停机不会丢失任何的数据
	everysec -- 每秒(调用一次系统函数 fdatasync)，将系统缓冲区中的数据写入硬盘，意外停机最多丢失1s的数据
	no -- 服务器不主动调用 fdatasync,由系统决定何时调用，意外宕机丢失的数据是不确定的
	always速度较慢，everysec和no速度都比较快，默认的配置是everysec

	AOF文件中的冗余命令(aof文件重写)，满足条件时，服务器会重写aof文件
	1.手动执行 bgrewriteaof 命令
	2.通过配置选项来触发服务器自动执行bgrewriteaof命令
	一：auto-aof-rewrite-min-size 64mb -- 触发aof文件重写所需要的最小体积
	二：auto-aof-rewrite-percentage 100 -- 这里是增量百分比，达到条件一，并且累计增量达到条件二
	以上两个条件是组合使用的....
	AOF --无论何时都不会阻塞服务器，因为执行的命令都是bg...后台的
	redis支持多个数据库是基于单机的，如果是集群就没有数据库的概念，另外redis是单线程的！

	结论 -- RDB方式适合数据的备份，AOF方式适合数据的存储，两种持久化可以同时使用

	 memcached与redis的区别？
	 redis相关：redis每秒可以处理10万次的读写操作，单个value的最大限制是1GB
	（其中字符串类型最大512m）,不像memcached只能保存1MB的数据
	 Redis的主要缺点，是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写
	 redis 支持：list,set,hash，SortedSet等数据结构
	 redis 支持：数据的持久化，(master - slave形式的数据备份)很多方面支持数据库的特性，也可以说redis是一个数据库系统
	 memcached：只是简单的key - value缓存。一个key，最大1M。批量读取方面性能占优势
	 ....

	 redis主从同步细节？
	 1>从节点执行slaveof命令
	 2>从节点只是保存了slaveof命令中主节点的信息，并没有立即发起复制
	 3>从节点内部的定时任务发现有主节点的信息，开始使用socket连接主节点
	 4>连接建立成功后，发送ping命令，希望得到pong命令响应，否则会进行重连
	 5>如果主节点设置了权限，那么就需要进行权限验证，如果验证失败，复制终止
	 6>权限验证通过后，进行数据同步，这是耗时最长的操作，主节点将把所有的数据全部发送给从节点
	 7>当主节点把当前的数据同步给从节点后，便完成了复制的建立流程
	 接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性

	 psync 命令的使用方式：
	　　命令格式为  psync{runId}{offset}
	　　runId：从节点所复制主节点的运行 id        
	　　offset：当前从节点已复制的数据偏移量

	主节点运行ID：
	每个redis启动的时候，都会生成一个40位的运行ID。        
	运行ID的主要作用是用来识别Redis节点。如果使用 ip+port 的方式，那么如果主节点重启修改了RDB/AOF数据
	从节点再基于偏移量进行复制将是不安全的。所以，当运行id变化后，从节点将进行全量复
	也就是说，redis重启后，默认从节点会进行全量复制

224.volatile关键字
	如果一个变量是用volatile修饰的，则java可以确保所有线程看到这个变量的值是一致的
	如果某个线程对这个变量进行了更新，则其他线程可以马上看到这个更新，这就是所谓的线程可见性..
	这里有必要了解一下cup高速缓存的逻辑，CPU高速缓存为某个CPU独有，只与在该CPU运行的线程有关
	主存(内存)-->高速缓存-->cpu -->程序执行完毕-->高速缓存(刷新到)-->主存
	上述中：如果是单线程没有问题，如果是多线程，则存在缓存一致性的问题

	解决缓存一致性的方案有2种
	1、总线加Lock#锁 -->是一种独占的方式，只能有一个cup运行，其他cup阻塞
	2、缓存一致性协议 -->(MESI协议)
	   核心思想：当某个cpu在写数据时，如果发现操作的数据是共享的变量，则会通知其他cpu该变量的缓存行是无效的
	   因此其他cpu再操作该变量时，发现该变量的缓存行是无效的，则会重新从主存中加载该数据

	什么是可见性？
	当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看到修改过的值

	当一个变量被volatile修饰后，表示着线程本地内存无效，当一个线程修改该共享变量后，此次修改会立即被更新到主内存中
	当其他线程读取共享变量时，它会直接从主内存中读取。synchronize和锁都可以保证可见性

	在Java内存模型中，为了效率是允许编译器和处理器对指令进行重排序，当然重排序它不会影响单线程的运行结果
	但是对多线程会有影响。Java提供volatile来保证一定的有序性。最著名的例子就是单例模式里面的DCL（双重检查锁）
	volatile可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层volatile是采用“内存屏障”来实现的

	在执行程序时为了提高性能，编译器和处理器通常会对指令做重排序
	编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序
	处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序

	假设代码有两条语句，代码顺序是语句1先于语句2执行；那么只要语句2不依赖于语句1的结果
	打乱它们的顺序对最终的结果没有影响的话，那么真正交给CPU去执行时，他们的顺序可以是没有限制的
	可以允许语句2先于语句1被CPU执行，和代码中的顺序不一致。

	为什么要重排序呢？
	Reordering是jvm针对现在cpu的一种优化，Reordering后的指令会在性能上有很大的提升...

	综合两点实现原理： 
	1，保证可见性（但不保证原子性） 
	2，使用内存屏障禁止指令的重新排序，内存屏障是一组指令，用来实现对内存操作的顺序限制
    
	java的并发采用的是共享内存的模型（实例域，静态域，数组元素存储在堆中），堆内存在线程之间共享....
	JMM (java内存模型) 通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证
	这里注意：本地内存其实是不存在的，是一个抽象的概念（是对缓存，寄存器，缓冲区等...的描述）

    JMM中，如果一个操作的执行结果需要对另一个操作可见，那么这两个操作必须要满足happens-before关系
	这里的两个操作既可以是在一个线程内，也可以是在不同的线程内

	注意，两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！！！
	happens-before仅仅要求前一个操作（执行结果）对后一个操作可见
	编译器和处理器在重排序时会遵循数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序
	as-if-serial语义：意思是不管如何重排序，程序的执行结果不能改变

	java内存模型对 ”数据竞争“的定义：
	在一个线程中写一个变量，在另一个线程中读这个变量，写和读不同步
	顺序一致性模型保证所有线程只能看到一致的操作执行顺序
	JMM不保证对long型和double型（64位）的读写操作具有原子性，而顺序一致性模型保证对所有的内存读-写操作具有原子性

	总线：数据是通过总线在处理器和内存之间传递的，通过一些列的步骤，这些步骤称之为总线事物（读事物，写事物）
	在一个处理器执行总线事物期间，总线会禁止其他所有的处理器和I\O设备执行内存的读写

225.java反射的机制理解，什么是java反射机制?
	在运行状态中，对于任意一个类，能获取这个类的所有属性和方法。对于任意一个对象，能调用它的方法和属性
	这种动态获取类信息以及调用对象方法的功能，就是反射。通过反射来理解泛型的本质：
	泛型通俗的理解就是，用来约束输入的值为同一类型，输入不同类型的值，在编译的过程中就会报错。通过反射
	我们可以绕过编译期，直接进入运行期。Class类，Field类，Method类，Constuctor类都是在运行期执行的

226.cron --- 表达式：
	1.  Seconds(秒)：	0--59秒
	2.  Minutes(分)：	0--59分
	3.  Hours(时)：	0--23小时
	4.  Day-of-Month(天)：	0--31日(这里注意特殊月份的日期)
	5.  Month(月):	可以用0-11 或用字符串
		“JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV and DEC” 表示
	6.  Day-of-Week(每周):	可以用数字1-7表示（1 ＝ 星期日）或用字符串“SUN, MON, TUE, 
		WED, THU, FRIand SAT”表示
	7.  Year (年，可选字段)正常情况下‘0 0 0 0 0 0’，就表示省略了年这个字段
	整体格式：秒--分--时--日--月--周--年
	有几个特殊字符，需要知道
	“?”字符：表示不确定的值
	“,”字符：指定数个值
	“-”字符：指定一个值的范围
	“/”：为特别单位，表示为“每”如“0/15”表示每隔15分钟执行一次,“0”表示为从“0”分开始
		“3/20”表示表示每隔20分钟执行一次，“3”表示从第3分钟开始执行
	“?”：表示每月的某一天，或某周的某一天
	“L”：用于每月，或每周，表示为每月的最后一天，或每个月的最后星期几如“6L”表示“每月的最后一个星期五”
	“W”：表示为最近工作日，如“15W”放在每月（day-of-month）字段上表示为“到本月15日最近的工作日”
	“#”：是用来指定“的”每月第n个工作日,例 在每周（day-of-week）这个字段中内容为"6#3" or "FRI#3" 则表示“每月第三个星期五”

	Cron表达式范例：
		每隔5秒执行一次：*/5 * * * * ?
		每隔1分钟执行一次：0 */1 * * * ?
		每天凌晨1点执行一次：0 0 1 * * ?
		每月1号凌晨1点执行一次：0 0 1 1 * ?
		每月最后一天23点执行一次：0 0 23 L * ?
		每周星期天凌晨1点实行一次：0 0 1 ? * L
		在26分、29分、33分执行一次：0 26,29,33 * * * ?
		每天的0点、13点、18点、21点都执行一次：0 0 0,13,18,21 * * ?

227.进程，线程。并发性，并行性
	并发性 --- 单核处理器上使用多个线程执行应用程序，可以理解为并发性
	并行性 --- 使用多个线程在多核处理器或多处理器的计算机上执行应用时，可以理解为并行性
    与每个java语言中的元素一样，线程(thread)是对象，两种创建线程的方式：
    一，继承Thread类，覆盖run()方法
    二，构建一个实现Runnable接口的类，然后创建一个Thread类对象并传递Runnable对象作为构造参数
    这里区别于以前肤浅的理解，一个处于执行状态的Thread对象(即：调用了start()方法)才能称之为线程
    Java提供中断机制来通知线程表明我们想要结束它。中断机制的特性是线程需要检查是否被中断
    而且还可以决定是否响应结束的请求。所以，线程可以忽略中断请求并且继续运行
    Thread 类还有一个boolean类型的属性来表明线程是否被中断。当你调用线程的interrupt()方法，
    就代表你把这个属性设置为true,而isInterrupted()方法仅返回属性值isInterrupted()和interrupted()
	都是检查线程是否被中断，但区别很大!isInterrupted()不会改变属性的值，只是返回属性的值，仅此而已
    interrupted()会把属性值设置为false，换句话说，它会复位状态值，如果call两次的话，
    第一次返回的是true因为线程被中断了，state=interrupted --> return true，接下来，它对state的值进行复位操作
	state=interrupted --> false，第二次返回的是false --因为state=interrupted已被置位为false

    并发应用的一个关键地方就是共享数据，这个对那些扩展Thread类或者实现Runnable接口的对象特别重要
    这里有一个ThreadLocal<T> 类，用的时候一般定义成static，Java中每个线程都有与之关联的ThreadLocalMap对象
	Thread对象中有一个ThreadLocal.ThreadLocalMap类型的成员变量，ThreadLocalMap是ThreadLocal类的一个静态
	内部类，每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改
	当ThreadLocal类型对象调用set方法时:
    一、Thread t = Thread.currentThread(); -- 获取当前线程对象
    二、ThreadLocalMap map = getMap(t); -- 通过当前线程对象获取当前线程对象维护的那个threadlocalmap
    三、map.set(this,value); -- 这里的this是本ThreadLocal对象，value就是线程自己要存储的值
    特别注意的是ThreadLocal与线程同步无关，并不是为了解决多线程共享变量问题
    而是为每个线程创建一个单独的变量副本，提供了保持对象的方法和避免参数传递的复杂性
    如果把threadLocal声明为非静态，则在类的每个实例中都会产生一个新对象，这是毫无意义的，只是增加了内存消耗

	ThreadLocal<T> tl = new ThreadLocal<>();
	t1.get()内部释义：1.获取当前线程  2.通过当前线程获取ThreadLocalMap对象 3.通过当前ThreadLocal对象即t1获取存储的值T
	ThreadLocal对象是唯一的，但是Thread的不是唯一的

228.树是一种数据结构，它是由n（n>=1）个有限节点组成一个具有层次关系的集合
	把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的，它具有以下的特点：
	(01) 每个节点有零个或多个子节点
	(02) 没有父节点的节点称为根节点
	(03) 每一个非根节点有且只有一个父节点
	(04) 除了根节点外，每个子节点可以分为多个不相交的子树

	一些基本概念：
	结点的度：结点拥有的子树的数目
	叶子：度为零的结点。
	分支结点：度不为零的结点。
	树的度：树中结点的最大的度。
	层次：根结点的层次为1，其余结点的层次等于该结点的双亲结点的层次加1。
	树的高度：树中结点的最大层次。
	无序树：如果树中结点的各子树之间的次序是不重要的，可以交换位置。
	有序树：如果树中结点的各子树之间的次序是重要的, 不可以交换位置。
	森林：0个或多个不相交的树组成。对森林加上一个根，森林即成为树；删去根，树即成为森林

	二叉树知多少 -- 最多有两棵子树的树被称为二叉树
	1. 满二叉树：二叉树中所有非叶子结点的度都是2，且叶子结点都在同一层次上

	2. 完全二叉树：如果一个二叉树与满二叉树前m个节点的结构相同，这样的二叉树被称为完全二叉树
	也就是说，如果把满二叉树从右至左、从下往上删除一些节点，剩余的结构就构成完全二叉树
	叶子结点只能出现在最下层和次下层，且最下层的叶子结点集中在树的左部。显然，一棵满二叉树必定是一棵完全二叉树
	而完全二叉树未必是满二叉树

	3. 哈夫曼树：core项目中有java实现

	4. 二叉搜索树（排序树）：也叫二叉查找树，满足以下条件
	左子树上的节点值均小于根节点值，右子树上的节点值均大于根节点值，左右子树也满足上述条件
	没有键值相等的节点(no duplicate nodes)，缺点：二叉排序树的最终形态与输入数据的顺序有关
	core项目中有java实现

	5. 平衡二叉树：
	为了克服二叉排序树的缺点，人们想出办法，使得一棵树的左右子树高度大致相等，AVL树：
	任一节点的左子树深度和右子树深度相差不超过1，我们用平衡因子衡量这种差异
	任意节点的平衡因子Balance(p)= heigth(p的左子树) - height（p的右子树）

	6. 红黑树是一种二叉查找树，但在每个结点上增加一个存储位表示结点的颜色(red或是black)，红黑树满足以下五个性质
	1) 每个结点或是红色或是黑色
	2) 根结点是黑色
	3) 每个叶结点是黑的
	4) 如果一个结点是红的，则它的两个儿子均是黑色
	5) 每个结点到其子孙结点的所有路径上包含相同数目的黑色结点
	旋转等，不好理解的部分

	7. B树、B+树：
	m阶B-Tree满足以下条件：(m阶就是树的高度是m)
	1>、每个节点最多拥有m个子树
	2>、根节点至少有2个子树
	3>、分支节点至少拥有m/2颗子树（除根节点和叶子节点外都是分支节点）
	4>、所有叶子节点都在同一层、每个节点最多可以有m-1个key，并且以升序排列
	插入或者删除元素都会导致节点发生裂变反应，有时候会非常麻烦，但正因为如此才让B树能够始终保持多路平衡
	这也是B树自身的一个优势：自平衡；B树主要应用于文件系统以及部分数据库索引，如MongoDB
	大部分关系型数据库索引则是使用B+树实现

	B-Tree与二叉查找树的对比:
	我们知道二叉查找树查询的时间复杂度是O(log₂N)，查找速度最快和比较次数最少，既然性能已经如此优秀
	但为什么实现索引是使用B-Tree而不是二叉查找树，关键因素是磁盘IO的次数，每次磁盘IO读取的数据我们称之为一页
	page，一页的大小与操作系统有关，一般为4k或者8k。这也就意味着读取一页数据的时候，实际上发生了一次磁盘IO
	数据库索引是存储在磁盘上，当表中的数据量比较大时，索引的大小也跟着增长，达到几个G甚至更多
	当我们利用索引进行查询的时候，不可能把索引全部加载到内存中，只能逐一加载每个磁盘页
	这里的磁盘页就对应索引树的节点，最坏的情况下磁盘IO的次数由树的高度来决定，减少磁盘IO的次数就必须要压缩树的高度
	让瘦高的树尽量变成矮胖的树，所以B-Tree就在这样伟大的时代背景下诞生了

	B+Tree -- B-Tree的变种，有着比B-Tree更高的查询性能，看下m阶B+Tree的特性：
	1> 有m个子树的节点包含有m个元素（B-Tree中是m-1）
	2> 根节点和分支节点中不保存数据，只用于索引，所有数据都保存在叶子节点中
	3> 所有分支节点和根节点都同时存在于子节点中，在子节点元素中是最大或者最小的元素
	4> 叶子节点会包含所有的关键字，以及指向数据记录的指针，并且叶子节点本身是根据关键字的大小从小到大顺序链接

	a、首先B+树的中间节点不存储卫星数据，所以同样大小的磁盘页可以容纳更多的节点元素，如此一来，相同数量的数据下
	   B+树就相对来说要更加矮胖些，磁盘IO的次数更少。
	b、由于只有叶子节点才保存卫星数据，B+树每次查询都要到叶子节点；而B树每次查询则不一样，最好的情况是根节点
	   最坏的情况是叶子节点，没有B+树稳定

	B+Tree与B-Tree的比较:
	1> 单节点可以存储更多的元素，使得查询磁盘IO次数更少
	2> 所有查询都要查找到叶子节点，查询性能稳定
	3> 所有叶子节点形成有序链表，便于范围查询

	8. 二叉堆：这里的堆并非是内存分区中的堆，堆通常可以被看做是树结构，满足以下两个性质
	1）堆中任意节点的值总是不大于（不小于）其子节点的值
	2）二叉堆是一棵完全二叉树。正是由于这样的性质，堆又被称为优先队列。根据性质一
	将任意节点不大于其子节点的堆称为最小堆或最小优先队列，反之称为最大堆或最大优先队列
	优先队列在操作系统作业调度的设计中有着举足轻重的作用
	二叉堆的构建时间复杂度是O(n)，构建过程
		给定一个数组直接按顺序排成二叉树，调整，从最后的非叶子节点开始调整
	二叉堆的插入时间复杂度是O(logn)，插入过程
		插入位置是完全二叉树的最后一个位置，然后进行调整
	二叉堆的删除操作，过程
		删除操作和插入操作正好相反，是从堆顶进行，删除堆顶的元素，然后把二叉树的最后一个节点移动到堆顶元素的位置，然后进行调整

	9. 线索二叉树：
	通过考察各种二叉链表，不管二叉树的形态如何，空链域的个数总是多过非空链域的个数。准确的说n个结点的二叉链表
	共有2n个链域，非空链域为n-1个，但其中的空链域却有n+1个，因此，提出了一种方法，利用原来的空链域存放指针
	指向树中其他结点。这种指针称为线索，线索化的实质就是将二叉链表中的空指针改为指向前驱或后继的线索
	lchild    ltag    data    rtag    rchild
	(1) ltag为0时指向该结点的左孩子，为1时指向该结点的前驱
	如果ptr->lchild为空，则存放指向中序遍历序列中该结点的前驱结点
	这个结点称为ptr的中序前驱
    (2) rtag为0时指向该结点的右孩子，为1时指向该结点的后继
    如果ptr->rchild为空，则存放指向中序遍历序列中该结点的后继结点
    这个结点称为ptr的中序后继
    注：请理解这里的中序遍历方式，中序遍历方式中的前驱和后继

229.零拷贝技术(zero-copy)
	简单一点来说，零拷贝就是一种避免CPU将数据从一块存储拷贝到另外一块存储的技术，零拷贝技术有下面几种
	1.直接I/O，对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输
	这类零拷贝技术针对的是操作系统内核并不需要对数据进行直接处理的情况，数据可以在应用程序地址空间的
	缓冲区和磁盘之间直接进行传输，完全不需要Linux操作系统内核提供的页缓存的支持
	2.在数据传输的过程中，避免数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间进行拷贝
	有的时候，应用程序在数据进行传输的过程中不需要对数据进行访问，那么，将数据从Linux的页缓存拷贝到用户进程
	的缓冲区中就可以完全避免，传输的数据在页缓存中就可以得到处理。在某些特殊的情况下，这种零拷贝技术可以获得
	较好的性能，Linux中提供类似的系统调用主要有mmap()，sendfile()以及splice()
	3.对数据在Linux的页缓存和用户进程的缓冲区之间的传输过程进行优化。该零拷贝技术侧重于灵活地处理数据在用户
	进程的缓冲区和操作系统的页缓存之间的拷贝操作。这种方法延续了传统的通信方式，但是更加灵活。在Linux中该方法
	主要利用了写时复制技术

	总结：前两类方法的目的主要是为了避免应用程序地址空间和操作系统内核地址空间这两者之间的缓冲区拷贝操作
	这两类零拷贝技术通常适用在某些特殊的情况下，比如要传送的数据不需要经过操作系统内核的处理或者不需要经
	过应用程序的处理。第三类方法则继承了传统的应用程序地址空间和操作系统内核地址空间之间数据传输的概念
	进而针对数据传输本身进行优化。我们知道，硬件和软件之间的数据传输可以通过使用DMA来进行，DMA进行数据传输
	的过程中几乎不需要CPU参与，这样就可以把CPU解放出来去做更多其他的事情，但是当数据需要在用户地址空间的缓
	冲区和Linux操作系统内核的页缓存之间进行传输的时候，并没有类似DMA这种工具可以使用，CPU需要全程参与到这
	种数据拷贝操作中，所以这第三类方法的目的是可以有效地改善数据在用户地址空间和操作系统内核地址空间之间传递的效率

230.密码学，最核心的就是加密算法
	加密算法的分类:
	1. 对称加密算法(symmetric cryptography),或称公共秘钥加密(common-key cryptography)
	   指使用相同密钥进行加密和解密的加密算法,对称加密算法的安全性取决于加密秘钥的保存情况,是不能随意泄露的
	2. 非对称加密算法(asymmetric cryptography),或称公开密钥加密(public-key cryptography)
	   指使用不同密钥进行加密和解密的加密算法,我们首先会生成两把钥匙,一把是公钥,可以随意公开,一把是私钥
	   公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密，所以叫非对称加密算法

	   同一种道理，我在换种说法
	   私钥和公钥是一对，谁都可以加解密，只是谁加密谁解密是看情景来用的
	   第一种情景是签名,使用私钥加密,公钥解密,用于让所有公钥所有者验证私钥所有者的身份并且用来防止私钥所有者发布
	   的内容被篡改.但是不用来保证内容不被他人获得
	   第二种情景是加密,用公钥加密,私钥解密,用于向公钥所有者发布信息,这个信息可能被他人篡改,但是无法被他人获得
	   两种模式:
		 认证模式,私钥加密,公钥解密是签名 -- 签名
		 加密模式,公钥加密,私钥解密是秘送 -- 加密

	   RSA(三个作者名字的首字母)算法是第一个能同时用于加密和数字签名的算法
	   RSA算法,私钥加密内容,只能公钥解密。公钥加密内容,只能私钥解密

	3. 哈希算法(hash,散列算法),或称为消息摘要算法,是一种单向算法,算法对目标信息生成一段特定长度的唯一的字符串
	   Hash值，生成后不能通过这个字符串重新获取目标信息,过程是不可逆的,因而是一种单向算法。摘要算法的本事就是
	   可以把一大段的字符串，例如本文的所有文字,映射到一个固定的字符串上,并且可以保证字符串是唯一的
	   摘要算法主要使用SHA算法
	   SHA(secure hash algorithm)安全散列算法，特点，抗碰撞,对于任意两个不同的数据,其hash值相同的可能性极小
	   抗篡改,对于一个数据，哪怕只改动其一个比特位,其hash值的变动也会非常大
		
	总结:
	非对称加密算法的运行速度比对称加密算法的速度慢很多,当我们需要加密大量数据时,建议使用对称加密算法
	对称加密算法不能实现签名,因此签名只能采用非对称加密算法
	由于对称加密算法的密钥管理是一个复杂的过程,密钥的管理直接决定着安全性,因此当数据量较小时
	可以考虑采用非对称加密算法
	通常采用的方式是: 采用非对称加密算法管理对称算法的密钥,然后用对称加密算法加密数据,
	这样我们就集成了两类加密算法的优点,速度与安全兼顾了

231.java注解，用一个词就可以描述注解，那就是元数据，即一种描述数据的数据，可以说注解就是源代码的元数据
	Annotation是一种应用于类、方法、参数、变量、构造器及包声明中的特殊修饰符，它是一种和代码紧耦合的
	而不像xml那样和代码是松耦合的描述，甚至是完全分离的，对于@Override注释你可能有些疑问，它什么都没做
	那它是如何检查在父类中有一个同名的函数呢，annotation仅仅是元数据，和业务逻辑没有任何关系Annotations
	仅仅提供它定义的属性(类/方法/包/域)的信息。Annotations的用户(同样是一些代码)来读取这些信息并实现必要的逻辑
	当我们使用Java的标注Annotations(例如@Override)时，JVM就是一个用户，它在字节码层面工作
	J2SE5.0版本在java.lang.annotation提供了四种元注解，专门注解其他的注解
	@Documented –注解是否将包含在JavaDoc中
	@Retention –什么时候使用该注解
	@Target –注解用于什么地方
	@Inherited – 是否允许子类继承该注解
	@Repeatable - 是Java1.8才加进来的，所以算是一个新的特性，可重复的

	//这是一个容器注解，什么是容器注解？就是用来存放其它注解的地方。它本身也是一个注解,按照规定，它里面必须
	要有一个value的属性，属性类型是一个被@Repeatable注解过的注解数组，注意它是数组，如果不好理解的话
	可以这样理解。Persons是一张总的标签，上面贴满了Person这种同类型但内容不一样的标签。把Persons给一个
	SuperMan贴上，相当于同时给他贴了程序员、产品经理、画家的标签
	@interface Persons {
    Person[]  value();
	}
	//注解上的元注解@Repeatable，什么样的注解会多次应用呢？通常是注解的值可以同时取多个
	举个例子，一个人他既是程序员又是产品经理，同时他还是个画家

	@Repeatable(Persons.class)
	@interface Person{
	    String role() default "";
	}
	@Person(role="artist")
	@Person(role="coder")
	@Person(role="PM")
	public class SuperMan{

	}

	那么，注解的内部到底是如何定义的呢？Annotations支持基本类型、类、String、枚举类型和数组,注释中所有的属性被
	定义成方法，并允许提供默认值。注解的定义-@interface，同class,interface一样，它也是一种类型
	注解只有成员变量，没有方法！注解的成员变量在注解的定义中以“无形参的方法”形式来声明
	其方法名定义了该成员变量的名字，其返回值定义了该成员变量的类型

	注解并非是所解释的代码本身的一部分。注解对于代码的运行效果没有直接影响，注解有许多用处，主要如下： 
	- 提供信息给编译器：编译器可以利用注解来探测错误和警告信息 
	- 编译阶段时的处理：软件工具可以用来利用注解信息来生成代码、Html文档或者做其它相应处理 
	- 运行时的处理：某些注解可以在程序运行的时候接受代码的提取

	注解主要针对的是编译器和其它工具软件，当开发者使用了Annotation修饰了类、方法、Field等成员之后
	这些Annotation不会自己生效，必须由开发者提供相应的代码来提取并处理Annotation信息，这些处理提取和处理
	Annotation的代码统称为APT（Annotation Processing Tool)

232.Event Loop-事件循环，什么是eventloop？
	事件循环被称作循环的原因在于，它一直在查找新的事件并且执行。一次循环的执行称之为tick(一瞬间，钩号)
	在这个循环里执行的代码称作task。指的是计算机系统的一种运行机制，JavaScript语言就采用这种机制
	来解决单线程运行带来的一些问题，"Event Loop是一个程序结构，用于等待和发送消息以及事件
	a programming construct that waits for and dispatches events or messages in a program."
	简单说，就是在程序中设置两个线程：一个负责程序本身的运行，称为"主线程"，另一个负责主线程与其他进程
	(主要是各种I/O操作)的通信，被称为"Event Loop线程"（可以译为"消息线程"）

234.Restful-理解，中文就是表现层状态转化，Representational state transfer
	R-这里是资源的意思，我们的请求路径是面向资源的。每一个（种）资源 --有唯一的一个url
	此url有自描述性，通过url配合http的请求方式，我们就知道请求需要哪个资源

	事实上，RESTful API的实现分了四个层级
	第一层次的Web API服务只是使用HTTP作为传输方式
	第二层次的Web API服务引入了资源的概念，每个资源有对应的标识符和表达
	第三层次的Web API服务使用不同的HTTP方法来进行不同的操作，并且使用HTTP状态码来表示不同的结果
	第四层次的Web API服务使用HATEOAS，在资源的表达中包含了链接信息，客户端可以根据链接来发现可以执行的动作

	这里的HATEOAS是什么鬼？
	Hypermedia as the engine of application state -- 超媒体即应用状态引擎，怎么理解？
	超媒体是什么? 当你浏览Web网页时，从一个连接跳到一个页面，再从另一个连接跳到另外一个页面，就是利用了超媒体的概念
	把一个个资源链接起来。即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么

	DO (data object)、与数据库表一一对应
	DTO (data transfer object)、远程调用对象
	BO (bussiness object)、业务逻辑层对象，一般是聚合了多个DO
	VO (view object)、前后端交互流转对象

235.对tomcat的理解
	server组件、一台物理机可以开启多个tomcat实例。一个server就是一个实例，这里可以理解一个server就是一台设备
	<--Server port ="8005" shutdown = ""SHUTDOWN"-->

	service组件、是用来关联(一个Engine)引擎和(多个Connector)连接器的。 这里可以理解一个service就是
	一个服务。每个连接器通过一个特定的端口和协议，接收入站请求并将其转发至相关联的引擎进行处理，因此一个
	service组件要包含一个引擎和一个或多个连接器

	connector组件、进入tomcat的请求，根据tomcat的工作模式可以分为两类
		a.作为应用程序服务器，请求来自于前端的web服务器。这可能是Apacha，nginx等(IIS)
		b.作为独立的服务器，请求来自于web浏览器
    常见于server.xml中的连接器通常有四种类型：
		1.http连接器
		2.SSL连接器
		3.AJP连接器
		4.proxy连接器
	engine组件、engine是servlet处理器的一个实例，servlet引擎

	host组件、位于engine容器中用于处理请求的主机或虚拟主机

	context组件、用于标识一个tomcat实例中的一个应用程序（一个应用程序的上下文）

	realm组件、表示一个安全上下文

	valve组件、类似于过滤器,一般工作于Engine范围内RemoteHostValve,RemoteAddrValve等

	一个完整的请求处理过程
	1> 用户请求发送到8080端口，被监听的http-connector获得
	2> connector将请求交给其所在的service内部的Engine来处理，并等待Engine响应
	3> Engine拿到请求的路径（localhost:8080/test/index.jsp），获取到相应的主机（localhost）
	4> 名为localhost的主机拿到 /test/index.jsp,匹配其所拥有的所有context,匹配路径为/text的context
	   从path=/text的context获得/index.jsp这个请求，然后在其mapping table中寻找/index.jsp对用的servlet
	5> 构造HttpServletRequest和HttpServletResponse对象，作为参数调用servlet的service方法(doGet，doPost等)
	6> context把执行完的HttpServletResponse对象返回给Host, Host -->Engine,Engine-->Connector,Connector-->Browser

236.Activiti--工作流引擎
	1.BPMN --Business Process Model and Notation:业务流程模型与符号
	是一套流程建模的标准，通俗一点讲就是一套建模规范，这里需要知道、JBPM 也是一个工作流引擎
	
	2.activiti是一个开源的工作流引擎。实现了BPMN2.0规范，可以发布设计好的流程定义，并通过api进行流程调度
	
	3.activiti 组成部分
	deployment -- 流程部署对象
	processDefinitions --流程部署定义
	processInstances -- 流程实例
	task -- 有角色参与的任务
	execution -- 执行计划(流程实例和流程执行中的所有节点都是Execution)
	processEngine -- 流程引擎
	RepositoryService -- 管理流程定义的仓库服务接口
	RuntimeService -- 流程执行服务类
	TaskService -- 任务服务类
	HistoryService -- 查询历史信息的类

237.spring系列问题汇总
	spring - 注解
		@ComponentScan--@ComponentScan告诉Spring哪个packages的用注解标识的类会被spring自动扫描并且装入bean容器
		@ComponentScan(basePackages = {"com.yixiang.np.service", "com.yixiang.np.utils"})
		@ComponentScans -- 暂时不知道

		@ControllerAdvice -- 该注解顾名思义增强器，对注解了Controller的类进行增强
		即把@ControllerAdvice注解的类内部使用了@ExceptionHandler、@InitBinder
		@ModelAttribute注解的方法应用到所有的@RequestMapping注解的方法，该注解作用对象为TYPE
		包括类、接口和枚举等在运行时有效，并且可以通过Spring扫描为bean组件

		@ExceptionHandler：统一处理某一类异常，从而能够减少代码重复率和复杂度
		该注解作用对象为方法，并且在运行时有效，value()可以指定异常类

		@ControllerAdvice：异常集中处理，更好的使业务逻辑与异常处理剥离开
		@ResponseStatus：可以将某种异常映射为HTTP状态码

		@Qualifier、合格者，如果有两个或多个serviceImpl实现了同一个接口，当我们需要注入此接口
		到业务类时，会报错，@Qualifier("name")，表明那个Impl才是我们需要的哪一个

		@SpringBootApplication相当于@EnableAutoConfiguration、@ComponentScan和@Configuration的合集

		@PathVariable -- http://....someUrl/{paramId},这种url路径时
		这时的paramId可通过 @Pathvariable注解绑定它传过来的值到方法的参数上
		这种可以绑定controller层mapping中的路径参数到相应的方法参数上
		
		@RequestHeader
		可以把Request请求header部分的值绑定到方法的参数上
		重点：此注解大小写不敏感 ！！！！ 那就是在使用 @RequestHeader的时候是大小写不敏感的
		即@RequestHeader(“Host”)和@RequestHeader(“host”)绑定的都是Host头信息
		记住在@PathVariable 、@RequestParam 和 @CookieValue 中都是大小写敏感的
		
		@CookieValue 
		可以把Request header中关于cookie的值绑定到方法的参数上
		
		@SessionAttributes --
		该注解用来绑定HttpSession中的attribute对象的值，便于在方法中的参数里使用
		该注解有value、types两个属性，可以通过名字和类型指定要使用的attribute对象

	spring-boot
	spring-boot2.0 默认的数据库连接池、hikariCP
	hikari-[hikari] 光 日本地名，CP-connectivity pool连接池
	springboot并不是对spring的增强，只是提供了一种快速使用spring的方式

	springboot加载框架之外的自定义文件的解决办法
	前两天在做springcloud框架下的项目的时候，用到有一个框架之外的文件需要进行读取
	当时在eclipse中编码时通过this.getClass().getResource来获取文件的路径，没有任何的问题，但是在打成jar以后
	这是打成jar包不是war，结果发现不能正常的读取我放在工程里面的文件，但是在jar里面对应的class路径下可以看到该文件
	后来将文件直接放到和我一个java文件平级的目录下，问题依然
	最后使用了InputStream inputStream=this.getClass().getResourceAsStream("/config/a.pfx")
	来读取才解决了问题

	spring mvc的流程或是实现原理？
	1.用户发送请求至前端控制器、dispatcherServlet，dispatcherServlet->handlerMapping（映射处理器）
	HandlerMapping根据url找到具体的处理器，生成处理器对象（有拦截器也在此时生成）一并返给dispatcherServlet

	2.dispatcherServlet通过HandlerAdapter(处理器适配器)调用处理器

	3.controller执行（即：处理器），并返回ModleAndView(包括模型数据和逻辑视图)

	4.handlerAdapter将controller执行结果ModelAndView返给dispatcherServlet

	5.dispatcherServlet将ModelAndView传给ViewReslover(视图解析器)

	6.Reslover返回具体的View给dispatcherServlet

	7.dispatcherServlet对View进行视图渲染（即将模型数据填充到视图中）

	8.dispatcherServlet响应用户

	springMVC与struts的区别（垃圾面试题）
	1.struts2的核心是基于一个Filter StrutsPreparedAndExcuteFilter
	  springmvc的核心是基于一个servlet(DispatcherServlet)前端控制器
	2.struts2是基于类开发，传递参数是通过类的属性,故需要多例开发 -- prototype
	  springmvc是基于类中的方法开发,即一个url对应一个方法,传递参数是
	  传递到方法的形参上,所以可以是多例，也可以是单例
	3.struts2采用值栈存储请求以及响应数据,OGNL对象导航图
	  springmvc通过request解析请求参数，响应数据存储在ModelAndView里

	spring、IOC容器三种自动注入方式：
	1.设值注入 -- setter方法
	  命名空间注入 -- 只是setter方法的简化
	2.构造注入 -- 通过construtor方法
	3.通过字段(Field)注入，一般用于注解
	  自动装配 -- 字段注入的一种方式

	spring cloud
	@SpringBootApplication相当于@Configuration、@EnableAutoConfiguration和@ComponentScan
	你也可以同时使用这3个注解。其中@Configuration、@ComponentScan是spring框架的语法，在spring 3.x就有了
	用于代码方式创建配置信息和扫描包。@EnableAutoConfiguration是spring boot语法，表示将使用自动配置
	你如果下载了spring boot源码，就会看到spring boot实现了很多starter应用，这些starter就是一些配置信息
	有点类似于docker，一组环境一种应用的概念，spring boot看到引入的starter包，就可以计算如何自动配置你的应用
	spring配置管理模块由于是spring boot核心来实现的，因此做了大量的工作，可以把一些启动参数进行外部配置
	这在传统的方案中是很难办到的，因为涉及到要改写第三方组件的问题，难度很大。比如web应用的绑定端口
	传统应用只能在tomcat配置文件里改，而spring cloud却可以放到远程，类似的还有数据库连接、安全框架配置等

	1.eureka
	注册中心 -- Eureka中的服务注册中心就是一个spring Boot工程
	服务的注册和发现
		向注册中心--注册一个--服务提供者
		@EnableDiscoveryClient or @EnableEurekaClient,这两个注解 --
		首先都是用在client端的(服务提供者工程的启动类上)，作用把自己注册到服务注册中心当中
		(当然要配置服务注册中心的地址)
		eureka server -- 一个注册中心
		eureka client -- 服务提供者
		@RestController = @Controller + @ResponseBody

	2.服务消费者：服务与服务的通讯是基于http restful的。Spring cloud有两种服务调用方式
	一种是ribbon+restTemplate，另一种是feign。ribbon是一个负载均衡客户端，可以很好的控制http和tcp的一些行为
	Feign默认集成了ribbon，Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用Feign
	只需要创建一个接口并注解。它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解
	Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果
	这里的负载均衡策略并不是轮询
	简而言之：Feign采用的是基于接口的注解，Feign整合了ribbon

	3.断路器(熔断器-- 保险)：Netflix开源了Hystrix组件，实现了断路器模式，SpringCloud对这一组件进行了整合
	在微服务架构中，一个请求需要调用多个服务是非常常见的。较底层的服务如果出现故障，会导致连锁故障
	当对特定的服务的调用的不可用达到一个阀值（Hystric 是5秒20次）断路器将会被打开
	@EnableHystrix  @EnableCircuitBreaker  @HystrixCommand(fallback="method")
	circuit -- se:kit 线路，电路等 circuit-breaker --断路器
	注解：@EnableCircuitBreaker  -- 启动类上开启断路器功能，@EnableHystrix --两者作用相同


	4.路由网关(Zuul) :在微服务架构中，需要几个基础的服务治理组件，包括服务注册与发现、服务消费、负载均衡、断路器、
	智能路由、配置管理等，由这几个基础组件相互协作，共同组建了一个简单的微服务系统
	在Spring Cloud微服务系统中，一种常见的负载均衡方式是，客户端的请求首先经过负载均衡（zuul、Ngnix）
	再到达服务网关（zuul集群），然后再到具体的服。服务统一注册到高可用的服务注册中心集群，服务的所有的配置文件
	由配置服务管理，配置服务的配置文件放在git仓库，方便开发人员随时改配置
	Zuul的主要功能是路由转发和过滤器。路由功能是微服务的一部分，比如／api/user转发到到user服务
	/api/shop转发到到shop服务。zuul默认和Ribbon结合实现了负载均衡的功能，FallbackProvider提供了如果某微服务挂掉
	后，进入自定义处理逻辑的功能。但是需要注意的是，这个熔断器不支持以url配置的路由，必须要用serviceId的方式路由的
	方式才能使用熔断器，zuul的熔断器主要目的和意义在于针对某个微服务的异常状态进行控制，并不能具体的针对某个具体的
	请求方法进行控制

	5.分布式配置管理:
	在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件
	在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地）
	也支持放在远程Git仓库中。在spring cloud config组件中，分两个角色，一是config server，二是config client
	这里需要搞清楚一个问题：
	springboot的配置文件命名：情况一，application.yml/properties。情况二，bootstrap.yml/properties
	两者在加载过程中是有区别的：
	1.bootstrap的加载先于application(bootstrap应用于程序上下文引导阶段，技术上，bootstrap.yml由
	  父Spring ApplicationContext加载)
	2.可以理解为，一个是系统级别的（不经常变动的）。另一个是应用级别的（相对来说是经常变动的）
	
	总结：配置可以做成高可用的 导入eureka包，server端和client端加入注册中心

	6.消息总线(bus)Spring Cloud Bus将分布式的节点用轻量的消息代理连接起来。它可以用于广播配置文件的更改或者
	服务之间的通讯，也可以用于监控。本文要讲述的是用Spring Cloud Bus实现通知微服务架构的配置文件的更改


	8.Spring Cloud Stream官方定义，构建消息驱动微服务的框架
	应用程序通过inputs或者outputs来与Spring Cloud Stream中binder交互，通过我们配置来binding
	而Spring Cloud Stream的binder负责与中间件交互。所以，我们只需要搞清楚如何与Spring Cloud Stream交互
	就可以方便的使用消息驱动
	1> Binder
	Binder是Spring Cloud Stream的一个抽象概念，是应用与消息中间件之间的粘合剂。目前Spring Cloud Stream实现了
	Kafka和RabbitMQ的binder。通过binder，可以很方便的连接中间件，可以动态的改变消息的destinations，对应于Kafka
	的topic，RabbitMQ的exchanges，这些都可以通过外部配置项来做到

	2> Publish-Subscribe
	消息的发布（Publish）和订阅（Subscribe）是事件驱动的经典模式。Spring Cloud Stream的数据交互也是基于这个思想
	生产者把消息通过某个topic广播出去（Spring Cloud Stream中的destinations）。其他的微服务，通过订阅特定topic
	来获取广播出来的消息来触发业务的进行。这种模式，极大的降低了生产者与消费者之间的耦合。即使有新的应用的引入
	也不需要破坏当前系统的整体结构

	3> Consumer Groups
	“Group”，如果使用过Kafka的童鞋并不会陌生。Spring Cloud Stream的这个分组概念的意思基本和Kafka一致
	微服务中动态的缩放同一个应用的数量以此来达到更高的处理能力是非常必须的。对于这种情况，同一个事件防止被重复消费
	只要把这些应用放置于同一个 “group” 中，就能够保证消息只会被其中一个应用消费一次

	4> Durability
	消息事件的持久化是必不可少的。Spring Cloud Stream可以动态的选择一个消息队列是持久化，还是present

	5> Bindings
	bindings是我们通过配置把应用和spring cloud stream的binder绑定在一起，之后我们只需要修改binding的配置
	来达到动态修改topic、exchange、type等一系列信息而不需要修改一行代码

	spring security核心接口解释
	securityContextHolder --- 用于存储安全上下文
	包括：当前用户是谁，该用户是否已经被认证，该用户拥有那些角色权限等...
	默认使用ThreadLocal策咯来存储安全上下文,与线程绑定的策咯，用户登陆时自动绑定，用户退出登陆时自动清除

	Authentication接口extends principal可以理解为身份/认证的最高抽象
	由这个顶级接口，我们可以得到用户拥有的权限信息列表，密码，用户细节信息，用户身份信息，认证信息
	getAuthorities()权限信息列表，默认是GrantedAuthority接口的一些实现类，通常是代表权限信息的一系列字符串
	getCredentials()密码信息，用户输入的密码字符串，在认证过后通常会被移除，用于保障安全
	getDetails()细节信息，web应用中的实现接口通常为 WebAuthenticationDetails
	它记录了访问者的ip地址和sessionId的值
	getPrincipal()最重要的身份信息，大部分情况下返回的是UserDetails接口的实现类，也是框架中的常用接口之一

	Spring Security是如何完成身份认证的？
	1.用户名和密码被过滤器获取到，封装成Authentication，通常情况下是UsernamePasswordAuthenticationToken
	2.AuthenticationManager身份管理器负责验证这个Authentication
	3.认证成功后AuthenticationManager身份管理器返回一个被填充满了信息的Authentication实例
	实例中包括上面提到的权限信息,身份信息,细节信息,但密码通常会被移除
	4.SecurityContextHolder安全上下文容器将第3步填充了信息的Authentication
	通过SecurityContextHolder.getContext().setAuthentication(…)方法,设置到其中
	这是一个抽象的认证流程，而整个过程中，如果不纠结于细节，其实只剩下一个AuthenticationManager
	AuthenticationManager身份认证管理器

	AuthenticationManager一般不直接认证，AuthenticationManager接口的一个常用实现类
	ProviderManager内部会维护一个List<AuthenticationProvider>列表,存放多种认证方式
	(用户名+密码,邮箱+密码，手机号码+密码，甚至，可能允许用户使用指纹登录)
	这里的AuthenticationProvider类似于shiro中的realm,在默认策略下,只需要通过一个AuthenticationProvider的认证
	即可被认为是登录成功，AuthenticationProvider最最常用的一个实现就是 DaoAuthenticationProvider
	DaoAuthenticationProvider
	1.根据用户名，加载用户信息
	2.完成信息比对(用户提供的信息和根据用户名加载出来的信息)
	3.如果比对成功，返回一个用户的真实信息

	UserDetails -- 接口它代表最详细的用户信息
	UserDetails与Authentication 这两个接口很相似
	Authentication的getCredentials()与UserDetails中的getPassword()需要被区分对待，前者是用户提交的密码凭证
	后者是用户正确的密码，认证器其实就是对这两者的比对
	Authentication中的getAuthorities()实际是由UserDetails的getAuthorities()传递而形成的

	UserDetailsService和AuthenticationProvider两者的职责常常被人们搞混:
	1. UserDetailsService只负责从特定的地方(通常是数据库),加载用户信息而已，仅此而已
	2. UserDetailsService常见的实现类有JdbcDaoImpl，InMemoryUserDetailsManager，
		前者从数据库加载用户，后者从内存中加载用户，也可以自己实现UserDetailsService，通常这更加灵活

	springSecurityFilterChain --- spring security核心过滤器链
	SecurityContextPersistenceFilter:
		两个主要职责：请求来临时，创建 SecurityContext安全上下文信息，请求结束时清空 SecurityContextHolder。
	HeaderWriterFilter: (文档中并未介绍，非核心过滤器) 
		用来给http响应添加一些Header,比如X-Frame-Options, X-XSS-Protection*，X-Content-Type-Options.
	CsrfFilter: 
		在spring4这个版本中被默认开启的一个过滤器，用于防止csrf攻击，了解前后端分离的人一定不会对这个攻击方式
		感到陌生，前后端使用json交互需要注意的一个问题
	LogoutFilter:
		顾名思义，处理注销的过滤器
	UsernamePasswordAuthenticationFilter:
		这个会重点分析，表单提交了username和password，被封装成token进行一系列的认证，便是主要通过这个过滤器完成的，在表单认证的方法中，这是最最关键的过滤器。
	RequestCacheAwareFilter: (文档中并未介绍，非核心过滤器) 
		内部维护了一个RequestCache，用于缓存request请求
	SecurityContextHolderAwareRequestFilter:
		此过滤器对ServletRequest进行了一次包装，使得request具有更加丰富的API
	AnonymousAuthenticationFilter:
		匿名身份过滤器，这个过滤器个人认为很重要，需要将它与UsernamePasswordAuthenticationFilter 放在一起比较理解，spring security为了兼容未登录的访问，也走了一套认证流程，只不过是一个匿名的身份。
	SessionManagementFilter:
		和session相关的过滤器，内部维护了一个SessionAuthenticationStrategy，两者组合使用，常用来防止 session-fixation protection attack，以及限制同一用户开启多个会话��数量
	ExceptionTranslationFilter: 
		直译成异常翻译过滤器，还是比较形象的，这个过滤器本身不处理异常，而是将认证过程中出现的异常交给内部维护的一些类去处理，具体是那些类下面详细介绍
	FilterSecurityInterceptor:
		这个过滤器决定了访问特定路径应该具备的权限，访问的用户的角色，权限是什么？访问的路径需要什么样的角色和权限？这些判断和处理都是由该类进行的。

	OAuth2.0四种授权模式
	客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）
	1. 授权码模式(authorization code)
	2. 简单模式(implicit)
	3. 密码模式(resource owner password credentials)
	4. 客户端模式(client credentials)

	spring事物管理器默认-->runtimeException事物回滚，检查型异常直接忽略，事物不回滚
	可以设置rollbackFor = Exception.class，嵌套事物同上。同时mysql不支持嵌套事物

238.Java中的枚举特点
	1、尽管声明大写字母的枚举常量不是强制性的，但最好是这样做
	2、枚举类型与类一样，可以包含字段，构造函数和方法以及枚举常量
	3、枚举构造函数默认是私有的。枚举类型中只允许使用私有构造函数。这就���������么你不能使用new运算符实例化枚举类型
	4、枚举常量仅在整个执行中创建一次。当您最初在代码中��用枚举常量时，将创建所有枚举常量。在创建每个枚举常量时
	   将调用相应的构造函数。其实枚举常量是枚举对象，只不过他们是静态常量而已
	5、枚举常量必须在字段、构造函数和方法(如果有的话)之前声明
	6、默认情况下，所有枚举类型都扩展自java.lang.Enum类。由于Java不支持多重继承，因此它们无法扩展到任何其他类
	   但是枚举类型可以实现任意数量的接口。枚举��型默认为final。它们不能被任何其他类型扩展
	7、枚举常量可以有自己的主体，称为Constant Specific Body。在该主体中，您可以定义字段和方法
	   但是，这些方法和字段在定义它们的常量特定体中是可见的
	8、枚举类型可以包含任意数量的静态初始化块 以及实例初始化块。由于java.lang.Enum该类实现了Comparable和Serializable接口
	   因此默认情况下所有枚举类型都是Comparable和Serializable。我们可以使用== 运算符比较枚举常量
	9、您可以使用values()方法检索任何枚举类型的枚举常量。values()方法返回一个枚举常量数组
	   ordinal()方法用于获取枚举类型中枚举常量的顺序
	10、枚举在编译期间提供类型安全性。这意味着如果您尝试分配除指定的枚举常量之外的任何值，您将收到编译时错误
	11、您可以在类外或类内定义枚举类型，但不能在方法或块内定义

239.Java中HashMap中桶的元素个数为什么超过8个，其内部结构才由链表转换成红黑树?
	要弄明白这个问题，我们首先要明白为什么要转换，这个问题比较简单，因为Map中桶的元素初始化是链表保存的，其查找性能是O(n)
	而树结构能将查找性能提升到O(logn)。当链表长度很小的时候，即使遍历，速度也非常快，但是当链表长度不断变长
	肯定会对查询性能有一定的影响，所以才需要转成树。至于为什么阈值是8..

	链表长度达到8就转成红黑树，当长度降到6就转成普通bin，bin就是bucket，即HashMap中hashCode值一样的元素保存的地方
	TreeNodes占用空间是普通Nodes的两倍，所以只有当bin包含足够多的节点时才会转成TreeNodes，而并非是一开始就将其转换成
	TreeNodes，说白了就是trade-off，空间和时间的权衡

	当hashCode离散性很好的时候，树型bin用到的概率非常小，因为数据均匀分布在每个bin中，几乎不会有bin中链表长度会达到阈值
	但是在随机hashCode下，离散性可能会变差，然而JDK又不能阻止用户实现这种不好的hash算法，因此就可能导致不均匀的数据分布
	不过理想情况下随机hashCode算法下所有bin中节点的分布频率会遵循泊松分布，我们可以看到
	一个bin中链表长度达到8个元素的概率为0.00000006，几乎是不可能事件。所以，之所以选择8，不是拍拍屁股决定的
	而是根据概率统计决定的。由此可见，发展30年的Java每一项改动和优化都是非常严谨和科学的

240.Linux上，ssh-keygen命令，生成RSA密钥对，-b参数指定生成位数，最小支持1024，默认是2048
	TM -- trademark 商标
	2. JCP -- Java Community Process ，Java社区进程，JCP成立于1998年，官网，由社会各界Java组成的社区
		规划和领导Java的发展，其成员可以在这里看到 

	3. JSR -- Java Specification Requests，Java规范请求，由JCP成员向委员会提交的Java发展议案，经过一系列流程后
		如果通过最终会体现在未来的Java中

	Example:JSR-175标准...

241.关于跨域问题的几点理解
	1. ✕ 动态请求就会有跨域的问题
	✔ 跨域只存在于浏览器端，不存在于安卓/ios/Node.js/python/java等其它环境
	2. ✕ 跨域就是请求发不出去了
	✔ 跨域请求能发出去，服务端能收到请求并正常返回结果，只是结果被浏览器拦截了

	之所以会跨域，是因为受到了同源策略的限制，同源策略要求源相同才能正常进行通信，即协议、域名、端口号都完全一致
	html中支持跨域的标签，<script>、<img>、<link>、<iframe>。websocket是不受同源策略限制的，没有跨域的问题，它是一种
	浏览器的API，websocket本质上是一种tcp连接

	跨域分为两种，一种是跨域的请求，一种是访问跨域的页面

	同源策略具体限制些什么呢？

	1.不能向工作在不同源的的服务请求数据(client to server)
	这里有个问题之前也困扰了我很久，就是为什么home.com加载的cdn.home.com/index.js可以向home.com发请求而不会跨域呢？
	其实home.com加载的JS是工作在home.com的，它的源不是提供JS的cdn，所以这个时候是没有跨域的问题的
	并且script标签能够加载非同源的资源，不受同源策略的影响
	
	2.无法获取不同源的document/cookie等BOM和DOM，可以说任何有关另外一个源的信息都无法得到(client to client)

242.什么是java的编解码技术，或者说java的序列化是怎么回事？
	当进行远程跨进程服务调用时，需要把被传输的java对象编码为字节数组或是ByteBuffer对象。而当远程服务读取到ByteBuffer对象
	或是字节数组时，需要将其解码为发送时的java对象，这被称为java的编解码技术。
	而java的序列化只是编解码技术的一种，在远程服务调用时很少直接使用java序列化进行消息的编解码和传输
	下面简单说下java序列化的种种缺陷
	第一、最致命的是，无法跨语言
	第二、序列化后的码流太大
	第三、序列化性能太低

	几种比较流行的编解码工具
	google -- protobuf 全称 google protocol buffers 基于二进制的方式编解码
	MessagePack 高效的二进制序列化框架

243.Nginx 能用来做什么？
	第一、静态代理，nginx擅长处理静态文件，是非常好的图片、文件服务器，把所有的静态文件放在nginx上可以使应用动静分离
	性能更好。为什么呢？epoll(freebsd上是kqueue)网络IO模型是nginx处理性能高的根本理由，但并不是所有的情况下都是epoll大获全胜的
	nginx处理请求是异步非阻塞的

	第二、负载均衡，nginx通过反向代理可以实现负载均衡，避免服务器单节点故障

	第三、限流，基于漏桶算法，在高并发的场景下非常实用

	第四、缓存、浏览器缓存，静态资源缓存用expire。代理层缓存

	第五、黑白名单等

244.在设计系统时，应该多思考墨菲定律
	一、任何事都没有表面看起来那么简单
	二、所有的事都会比你预计的时间长
	三、可能出错的事总会出错
	四、如果你担心某种情况发生，那么它就更有可能发生

	在划分系统时，也要思考康威定律
	一、系统架构是公司组织架构的反应
	二、应该按照业务闭环进行系统拆分/组织架构划分，实现闭环/高内聚/低耦合，减少沟通成本
	三、如果沟通出现问题，那么就应该考虑进行系统和组织架构的调整
	四、在合适的时机进行系统拆分，不要一开始就把服务/系统拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高

245.sql语句中<>与!=等价，都是表示不等与的意思
	union与union all的区别，前者取唯一记录(去重)，后者取所有的记录，当然后者的效率要高一下

246.synchronized 与 reentrantLock的区别
	synchronized是由jvm实现，reentrantlock是jdk实现的
	两者性能在synchronized优化之后差不多

	reentrantlock独有的一些功能(手动加锁、解锁)
	一、可以指定是公平锁还是非公平锁（默认非公平锁）、synchronized只能是非公平锁。这里所谓的公平就是：
		先等待的线程先获得锁...
	二、提供了一个Condition类，可以分组唤醒需要唤醒的类
	三、提供能够中断等待锁的机制，lock.interruptibly()

	性能好的原因：自旋锁，循环调用CAS操作，避免了使线程进入内核态的阻塞状态
